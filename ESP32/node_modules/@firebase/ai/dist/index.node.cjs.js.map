{"version":3,"file":"index.node.cjs.js","sources":["../src/constants.ts","../src/errors.ts","../src/types/enums.ts","../src/types/responses.ts","../src/types/error.ts","../src/types/schema.ts","../src/types/imagen/requests.ts","../src/public-types.ts","../src/backend.ts","../src/helpers.ts","../src/service.ts","../src/factory-node.ts","../src/models/utils.ts","../src/models/ai-model.ts","../src/logger.ts","../src/requests/request.ts","../src/requests/response-helpers.ts","../src/googleai-mappers.ts","../src/requests/stream-reader.ts","../src/requests/hybrid-helpers.ts","../src/methods/generate-content.ts","../src/requests/request-helpers.ts","../src/methods/chat-session-helpers.ts","../src/methods/chat-session.ts","../src/methods/count-tokens.ts","../src/models/generative-model.ts","../src/methods/live-session.ts","../src/models/live-generative-model.ts","../src/models/imagen-model.ts","../src/websocket.ts","../src/models/template-generative-model.ts","../src/models/template-imagen-model.ts","../src/requests/schema-builder.ts","../src/requests/imagen-image-format.ts","../src/methods/live-session-helpers.ts","../src/api.ts","../src/index.node.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { version } from '../package.json';\n\nexport const AI_TYPE = 'AI';\n\nexport const DEFAULT_LOCATION = 'us-central1';\n\nexport const DEFAULT_DOMAIN = 'firebasevertexai.googleapis.com';\n\nexport const STAGING_URL =\n  'https://staging-firebasevertexai.sandbox.googleapis.com';\n\nexport const DEFAULT_API_VERSION = 'v1beta';\n\nexport const PACKAGE_VERSION = version;\n\nexport const LANGUAGE_TAG = 'gl-js';\n\nexport const DEFAULT_FETCH_TIMEOUT_MS = 180 * 1000;\n\n/**\n * Defines the name of the default in-cloud model to use for hybrid inference.\n */\nexport const DEFAULT_HYBRID_IN_CLOUD_MODEL = 'gemini-2.0-flash-lite';\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseError } from '@firebase/util';\nimport { AIErrorCode, CustomErrorData } from './types';\nimport { AI_TYPE } from './constants';\n\n/**\n * Error class for the Firebase AI SDK.\n *\n * @public\n */\nexport class AIError extends FirebaseError {\n  /**\n   * Constructs a new instance of the `AIError` class.\n   *\n   * @param code - The error code from {@link (AIErrorCode:type)}.\n   * @param message - A human-readable message describing the error.\n   * @param customErrorData - Optional error data.\n   */\n  constructor(\n    readonly code: AIErrorCode,\n    message: string,\n    readonly customErrorData?: CustomErrorData\n  ) {\n    // Match error format used by FirebaseError from ErrorFactory\n    const service = AI_TYPE;\n    const fullCode = `${service}/${code}`;\n    const fullMessage = `${service}: ${message} (${fullCode})`;\n    super(code, fullMessage);\n\n    // FirebaseError initializes a stack trace, but it assumes the error is created from the error\n    // factory. Since we break this assumption, we set the stack trace to be originating from this\n    // constructor.\n    // This is only supported in V8.\n    if (Error.captureStackTrace) {\n      // Allows us to initialize the stack trace without including the constructor itself at the\n      // top level of the stack trace.\n      Error.captureStackTrace(this, AIError);\n    }\n\n    // Allows instanceof AIError in ES5/ES6\n    // https://github.com/Microsoft/TypeScript-wiki/blob/master/Breaking-Changes.md#extending-built-ins-like-error-array-and-map-may-no-longer-work\n    // TODO(dlarocque): Replace this with `new.target`: https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-2.html#support-for-newtarget\n    //                   which we can now use since we no longer target ES5.\n    Object.setPrototypeOf(this, AIError.prototype);\n\n    // Since Error is an interface, we don't inherit toString and so we define it ourselves.\n    this.toString = () => fullMessage;\n  }\n}\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Role is the producer of the content.\n * @public\n */\nexport type Role = (typeof POSSIBLE_ROLES)[number];\n\n/**\n * Possible roles.\n * @public\n */\nexport const POSSIBLE_ROLES = ['user', 'model', 'function', 'system'] as const;\n\n/**\n * Harm categories that would cause prompts or candidates to be blocked.\n * @public\n */\nexport const HarmCategory = {\n  HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH',\n  HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n  HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT',\n  HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'\n} as const;\n\n/**\n * Harm categories that would cause prompts or candidates to be blocked.\n * @public\n */\nexport type HarmCategory = (typeof HarmCategory)[keyof typeof HarmCategory];\n\n/**\n * Threshold above which a prompt or candidate will be blocked.\n * @public\n */\nexport const HarmBlockThreshold = {\n  /**\n   * Content with `NEGLIGIBLE` will be allowed.\n   */\n  BLOCK_LOW_AND_ABOVE: 'BLOCK_LOW_AND_ABOVE',\n  /**\n   * Content with `NEGLIGIBLE` and `LOW` will be allowed.\n   */\n  BLOCK_MEDIUM_AND_ABOVE: 'BLOCK_MEDIUM_AND_ABOVE',\n  /**\n   * Content with `NEGLIGIBLE`, `LOW`, and `MEDIUM` will be allowed.\n   */\n  BLOCK_ONLY_HIGH: 'BLOCK_ONLY_HIGH',\n  /**\n   * All content will be allowed.\n   */\n  BLOCK_NONE: 'BLOCK_NONE',\n  /**\n   * All content will be allowed. This is the same as `BLOCK_NONE`, but the metadata corresponding\n   * to the {@link (HarmCategory:type)} will not be present in the response.\n   */\n  OFF: 'OFF'\n} as const;\n\n/**\n * Threshold above which a prompt or candidate will be blocked.\n * @public\n */\nexport type HarmBlockThreshold =\n  (typeof HarmBlockThreshold)[keyof typeof HarmBlockThreshold];\n\n/**\n * This property is not supported in the Gemini Developer API ({@link GoogleAIBackend}).\n *\n * @public\n */\nexport const HarmBlockMethod = {\n  /**\n   * The harm block method uses both probability and severity scores.\n   */\n  SEVERITY: 'SEVERITY',\n  /**\n   * The harm block method uses the probability score.\n   */\n  PROBABILITY: 'PROBABILITY'\n} as const;\n\n/**\n * This property is not supported in the Gemini Developer API ({@link GoogleAIBackend}).\n *\n * @public\n */\nexport type HarmBlockMethod =\n  (typeof HarmBlockMethod)[keyof typeof HarmBlockMethod];\n\n/**\n * Probability that a prompt or candidate matches a harm category.\n * @public\n */\nexport const HarmProbability = {\n  /**\n   * Content has a negligible chance of being unsafe.\n   */\n  NEGLIGIBLE: 'NEGLIGIBLE',\n  /**\n   * Content has a low chance of being unsafe.\n   */\n  LOW: 'LOW',\n  /**\n   * Content has a medium chance of being unsafe.\n   */\n  MEDIUM: 'MEDIUM',\n  /**\n   * Content has a high chance of being unsafe.\n   */\n  HIGH: 'HIGH'\n} as const;\n\n/**\n * Probability that a prompt or candidate matches a harm category.\n * @public\n */\nexport type HarmProbability =\n  (typeof HarmProbability)[keyof typeof HarmProbability];\n\n/**\n * Harm severity levels.\n * @public\n */\nexport const HarmSeverity = {\n  /**\n   * Negligible level of harm severity.\n   */\n  HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE',\n  /**\n   * Low level of harm severity.\n   */\n  HARM_SEVERITY_LOW: 'HARM_SEVERITY_LOW',\n  /**\n   * Medium level of harm severity.\n   */\n  HARM_SEVERITY_MEDIUM: 'HARM_SEVERITY_MEDIUM',\n  /**\n   * High level of harm severity.\n   */\n  HARM_SEVERITY_HIGH: 'HARM_SEVERITY_HIGH',\n  /**\n   * Harm severity is not supported.\n   *\n   * @remarks\n   * The GoogleAI backend does not support `HarmSeverity`, so this value is used as a fallback.\n   */\n  HARM_SEVERITY_UNSUPPORTED: 'HARM_SEVERITY_UNSUPPORTED'\n} as const;\n\n/**\n * Harm severity levels.\n * @public\n */\nexport type HarmSeverity = (typeof HarmSeverity)[keyof typeof HarmSeverity];\n\n/**\n * Reason that a prompt was blocked.\n * @public\n */\nexport const BlockReason = {\n  /**\n   * Content was blocked by safety settings.\n   */\n  SAFETY: 'SAFETY',\n  /**\n   * Content was blocked, but the reason is uncategorized.\n   */\n  OTHER: 'OTHER',\n  /**\n   * Content was blocked because it contained terms from the terminology blocklist.\n   */\n  BLOCKLIST: 'BLOCKLIST',\n  /**\n   * Content was blocked due to prohibited content.\n   */\n  PROHIBITED_CONTENT: 'PROHIBITED_CONTENT'\n} as const;\n\n/**\n * Reason that a prompt was blocked.\n * @public\n */\nexport type BlockReason = (typeof BlockReason)[keyof typeof BlockReason];\n\n/**\n * Reason that a candidate finished.\n * @public\n */\nexport const FinishReason = {\n  /**\n   * Natural stop point of the model or provided stop sequence.\n   */\n  STOP: 'STOP',\n  /**\n   * The maximum number of tokens as specified in the request was reached.\n   */\n  MAX_TOKENS: 'MAX_TOKENS',\n  /**\n   * The candidate content was flagged for safety reasons.\n   */\n  SAFETY: 'SAFETY',\n  /**\n   * The candidate content was flagged for recitation reasons.\n   */\n  RECITATION: 'RECITATION',\n  /**\n   * Unknown reason.\n   */\n  OTHER: 'OTHER',\n  /**\n   * The candidate content contained forbidden terms.\n   */\n  BLOCKLIST: 'BLOCKLIST',\n  /**\n   * The candidate content potentially contained prohibited content.\n   */\n  PROHIBITED_CONTENT: 'PROHIBITED_CONTENT',\n  /**\n   * The candidate content potentially contained Sensitive Personally Identifiable Information (SPII).\n   */\n  SPII: 'SPII',\n  /**\n   * The function call generated by the model was invalid.\n   */\n  MALFORMED_FUNCTION_CALL: 'MALFORMED_FUNCTION_CALL'\n} as const;\n\n/**\n * Reason that a candidate finished.\n * @public\n */\nexport type FinishReason = (typeof FinishReason)[keyof typeof FinishReason];\n\n/**\n * @public\n */\nexport const FunctionCallingMode = {\n  /**\n   * Default model behavior; model decides to predict either a function call\n   * or a natural language response.\n   */\n  AUTO: 'AUTO',\n  /**\n   * Model is constrained to always predicting a function call only.\n   * If `allowed_function_names` is set, the predicted function call will be\n   * limited to any one of `allowed_function_names`, else the predicted\n   * function call will be any one of the provided `function_declarations`.\n   */\n  ANY: 'ANY',\n  /**\n   * Model will not predict any function call. Model behavior is same as when\n   * not passing any function declarations.\n   */\n  NONE: 'NONE'\n} as const;\n\n/**\n * @public\n */\nexport type FunctionCallingMode =\n  (typeof FunctionCallingMode)[keyof typeof FunctionCallingMode];\n\n/**\n * Content part modality.\n * @public\n */\nexport const Modality = {\n  /**\n   * Unspecified modality.\n   */\n  MODALITY_UNSPECIFIED: 'MODALITY_UNSPECIFIED',\n  /**\n   * Plain text.\n   */\n  TEXT: 'TEXT',\n  /**\n   * Image.\n   */\n  IMAGE: 'IMAGE',\n  /**\n   * Video.\n   */\n  VIDEO: 'VIDEO',\n  /**\n   * Audio.\n   */\n  AUDIO: 'AUDIO',\n  /**\n   * Document (for example, PDF).\n   */\n  DOCUMENT: 'DOCUMENT'\n} as const;\n\n/**\n * Content part modality.\n * @public\n */\nexport type Modality = (typeof Modality)[keyof typeof Modality];\n\n/**\n * Generation modalities to be returned in generation responses.\n *\n * @beta\n */\nexport const ResponseModality = {\n  /**\n   * Text.\n   * @beta\n   */\n  TEXT: 'TEXT',\n  /**\n   * Image.\n   * @beta\n   */\n  IMAGE: 'IMAGE',\n  /**\n   * Audio.\n   * @beta\n   */\n  AUDIO: 'AUDIO'\n} as const;\n\n/**\n * Generation modalities to be returned in generation responses.\n *\n * @beta\n */\nexport type ResponseModality =\n  (typeof ResponseModality)[keyof typeof ResponseModality];\n\n/**\n * Determines whether inference happens on-device or in-cloud.\n *\n * @remarks\n * <b>PREFER_ON_DEVICE:</b> Attempt to make inference calls using an\n * on-device model. If on-device inference is not available, the SDK\n * will fall back to using a cloud-hosted model.\n * <br/>\n * <b>ONLY_ON_DEVICE:</b> Only attempt to make inference calls using an\n * on-device model. The SDK will not fall back to a cloud-hosted model.\n * If on-device inference is not available, inference methods will throw.\n * <br/>\n * <b>ONLY_IN_CLOUD:</b> Only attempt to make inference calls using a\n * cloud-hosted model. The SDK will not fall back to an on-device model.\n * <br/>\n * <b>PREFER_IN_CLOUD:</b> Attempt to make inference calls to a\n * cloud-hosted model. If not available, the SDK will fall back to an\n * on-device model.\n *\n * @beta\n */\nexport const InferenceMode = {\n  'PREFER_ON_DEVICE': 'prefer_on_device',\n  'ONLY_ON_DEVICE': 'only_on_device',\n  'ONLY_IN_CLOUD': 'only_in_cloud',\n  'PREFER_IN_CLOUD': 'prefer_in_cloud'\n} as const;\n\n/**\n * Determines whether inference happens on-device or in-cloud.\n *\n * @beta\n */\nexport type InferenceMode = (typeof InferenceMode)[keyof typeof InferenceMode];\n\n/**\n * Indicates whether inference happened on-device or in-cloud.\n *\n * @beta\n */\nexport const InferenceSource = {\n  'ON_DEVICE': 'on_device',\n  'IN_CLOUD': 'in_cloud'\n} as const;\n\n/**\n * Indicates whether inference happened on-device or in-cloud.\n *\n * @beta\n */\nexport type InferenceSource =\n  (typeof InferenceSource)[keyof typeof InferenceSource];\n\n/**\n * Represents the result of the code execution.\n *\n * @beta\n */\nexport const Outcome = {\n  UNSPECIFIED: 'OUTCOME_UNSPECIFIED',\n  OK: 'OUTCOME_OK',\n  FAILED: 'OUTCOME_FAILED',\n  DEADLINE_EXCEEDED: 'OUTCOME_DEADLINE_EXCEEDED'\n};\n\n/**\n * Represents the result of the code execution.\n *\n * @beta\n */\nexport type Outcome = (typeof Outcome)[keyof typeof Outcome];\n\n/**\n * The programming language of the code.\n *\n * @beta\n */\nexport const Language = {\n  UNSPECIFIED: 'LANGUAGE_UNSPECIFIED',\n  PYTHON: 'PYTHON'\n};\n\n/**\n * The programming language of the code.\n *\n * @beta\n */\nexport type Language = (typeof Language)[keyof typeof Language];\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Content, FunctionCall, InlineDataPart } from './content';\nimport {\n  BlockReason,\n  FinishReason,\n  HarmCategory,\n  HarmProbability,\n  HarmSeverity,\n  InferenceSource,\n  Modality\n} from './enums';\n\n/**\n * Result object returned from {@link GenerativeModel.generateContent} call.\n *\n * @public\n */\nexport interface GenerateContentResult {\n  response: EnhancedGenerateContentResponse;\n}\n\n/**\n * Result object returned from {@link GenerativeModel.generateContentStream} call.\n * Iterate over `stream` to get chunks as they come in and/or\n * use the `response` promise to get the aggregated response when\n * the stream is done.\n *\n * @public\n */\nexport interface GenerateContentStreamResult {\n  stream: AsyncGenerator<EnhancedGenerateContentResponse>;\n  response: Promise<EnhancedGenerateContentResponse>;\n}\n\n/**\n * Response object wrapped with helper methods.\n *\n * @public\n */\nexport interface EnhancedGenerateContentResponse\n  extends GenerateContentResponse {\n  /**\n   * Returns the text string from the response, if available.\n   * Throws if the prompt or candidate was blocked.\n   */\n  text: () => string;\n  /**\n   * Aggregates and returns every {@link InlineDataPart} from the first candidate of\n   * {@link GenerateContentResponse}.\n   *\n   * @throws If the prompt or candidate was blocked.\n   */\n  inlineDataParts: () => InlineDataPart[] | undefined;\n  /**\n   * Aggregates and returns every {@link FunctionCall} from the first candidate of\n   * {@link GenerateContentResponse}.\n   *\n   * @throws If the prompt or candidate was blocked.\n   */\n  functionCalls: () => FunctionCall[] | undefined;\n  /**\n   * Aggregates and returns every {@link TextPart} with their `thought` property set\n   * to `true` from the first candidate of {@link GenerateContentResponse}.\n   *\n   * @throws If the prompt or candidate was blocked.\n   *\n   * @remarks\n   * Thought summaries provide a brief overview of the model's internal thinking process,\n   * offering insight into how it arrived at the final answer. This can be useful for\n   * debugging, understanding the model's reasoning, and verifying its accuracy.\n   *\n   * Thoughts will only be included if {@link ThinkingConfig.includeThoughts} is\n   * set to `true`.\n   */\n  thoughtSummary: () => string | undefined;\n  /**\n   * Indicates whether inference happened on-device or in-cloud.\n   *\n   * @beta\n   */\n  inferenceSource?: InferenceSource;\n}\n\n/**\n * Individual response from {@link GenerativeModel.generateContent} and\n * {@link GenerativeModel.generateContentStream}.\n * `generateContentStream()` will return one in each chunk until\n * the stream is done.\n * @public\n */\nexport interface GenerateContentResponse {\n  candidates?: GenerateContentCandidate[];\n  promptFeedback?: PromptFeedback;\n  usageMetadata?: UsageMetadata;\n}\n\n/**\n * Usage metadata about a {@link GenerateContentResponse}.\n *\n * @public\n */\nexport interface UsageMetadata {\n  promptTokenCount: number;\n  candidatesTokenCount: number;\n  /**\n   * The number of tokens used by the model's internal \"thinking\" process.\n   */\n  thoughtsTokenCount?: number;\n  totalTokenCount: number;\n  /**\n   * The number of tokens used by tools.\n   */\n  toolUsePromptTokenCount?: number;\n  promptTokensDetails?: ModalityTokenCount[];\n  candidatesTokensDetails?: ModalityTokenCount[];\n  /**\n   * A list of tokens used by tools, broken down by modality.\n   */\n  toolUsePromptTokensDetails?: ModalityTokenCount[];\n}\n\n/**\n * Represents token counting info for a single modality.\n *\n * @public\n */\nexport interface ModalityTokenCount {\n  /** The modality associated with this token count. */\n  modality: Modality;\n  /** The number of tokens counted. */\n  tokenCount: number;\n}\n\n/**\n * If the prompt was blocked, this will be populated with `blockReason` and\n * the relevant `safetyRatings`.\n * @public\n */\nexport interface PromptFeedback {\n  blockReason?: BlockReason;\n  safetyRatings: SafetyRating[];\n  /**\n   * A human-readable description of the `blockReason`.\n   *\n   * This property is only supported in the Vertex AI Gemini API ({@link VertexAIBackend}).\n   */\n  blockReasonMessage?: string;\n}\n\n/**\n * A candidate returned as part of a {@link GenerateContentResponse}.\n * @public\n */\nexport interface GenerateContentCandidate {\n  index: number;\n  content: Content;\n  finishReason?: FinishReason;\n  finishMessage?: string;\n  safetyRatings?: SafetyRating[];\n  citationMetadata?: CitationMetadata;\n  groundingMetadata?: GroundingMetadata;\n  urlContextMetadata?: URLContextMetadata;\n}\n\n/**\n * Citation metadata that may be found on a {@link GenerateContentCandidate}.\n * @public\n */\nexport interface CitationMetadata {\n  citations: Citation[];\n}\n\n/**\n * A single citation.\n * @public\n */\nexport interface Citation {\n  startIndex?: number;\n  endIndex?: number;\n  uri?: string;\n  license?: string;\n  /**\n   * The title of the cited source, if available.\n   *\n   * This property is only supported in the Vertex AI Gemini API ({@link VertexAIBackend}).\n   */\n  title?: string;\n  /**\n   * The publication date of the cited source, if available.\n   *\n   * This property is only supported in the Vertex AI Gemini API ({@link VertexAIBackend}).\n   */\n  publicationDate?: Date;\n}\n\n/**\n * Metadata returned when grounding is enabled.\n *\n * Currently, only Grounding with Google Search is supported (see {@link GoogleSearchTool}).\n *\n * Important: If using Grounding with Google Search, you are required to comply with the\n * \"Grounding with Google Search\" usage requirements for your chosen API provider: {@link https://ai.google.dev/gemini-api/terms#grounding-with-google-search | Gemini Developer API}\n * or Vertex AI Gemini API (see {@link https://cloud.google.com/terms/service-terms | Service Terms}\n * section within the Service Specific Terms).\n *\n * @public\n */\nexport interface GroundingMetadata {\n  /**\n   * Google Search entry point for web searches. This contains an HTML/CSS snippet that must be\n   * embedded in an app to display a Google Search entry point for follow-up web searches related to\n   * a model's \"Grounded Response\".\n   */\n  searchEntryPoint?: SearchEntrypoint;\n  /**\n   * A list of {@link GroundingChunk} objects. Each chunk represents a piece of retrieved content\n   * (for example, from a web page). that the model used to ground its response.\n   */\n  groundingChunks?: GroundingChunk[];\n  /**\n   * A list of {@link GroundingSupport} objects. Each object details how specific segments of the\n   * model's response are supported by the `groundingChunks`.\n   */\n  groundingSupports?: GroundingSupport[];\n  /**\n   * A list of web search queries that the model performed to gather the grounding information.\n   * These can be used to allow users to explore the search results themselves.\n   */\n  webSearchQueries?: string[];\n  /**\n   * @deprecated Use {@link GroundingSupport} instead.\n   */\n  retrievalQueries?: string[];\n}\n\n/**\n * Google search entry point.\n *\n * @public\n */\nexport interface SearchEntrypoint {\n  /**\n   * HTML/CSS snippet that must be embedded in a web page. The snippet is designed to avoid\n   * undesired interaction with the rest of the page's CSS.\n   *\n   * To ensure proper rendering and prevent CSS conflicts, it is recommended\n   * to encapsulate this `renderedContent` within a shadow DOM when embedding it\n   * into a webpage. See {@link https://developer.mozilla.org/en-US/docs/Web/API/Web_components/Using_shadow_DOM | MDN: Using shadow DOM}.\n   *\n   * @example\n   * ```javascript\n   * const container = document.createElement('div');\n   * document.body.appendChild(container);\n   * container.attachShadow({ mode: 'open' }).innerHTML = renderedContent;\n   * ```\n   */\n  renderedContent?: string;\n}\n\n/**\n * Represents a chunk of retrieved data that supports a claim in the model's response. This is part\n * of the grounding information provided when grounding is enabled.\n *\n * @public\n */\nexport interface GroundingChunk {\n  /**\n   * Contains details if the grounding chunk is from a web source.\n   */\n  web?: WebGroundingChunk;\n}\n\n/**\n * A grounding chunk from the web.\n *\n * Important: If using Grounding with Google Search, you are required to comply with the\n * {@link https://cloud.google.com/terms/service-terms | Service Specific Terms} for \"Grounding with Google Search\".\n *\n * @public\n */\nexport interface WebGroundingChunk {\n  /**\n   * The URI of the retrieved web page.\n   */\n  uri?: string;\n  /**\n   * The title of the retrieved web page.\n   */\n  title?: string;\n  /**\n   * The domain of the original URI from which the content was retrieved.\n   *\n   * This property is only supported in the Vertex AI Gemini API ({@link VertexAIBackend}).\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this property will be\n   * `undefined`.\n   */\n  domain?: string;\n}\n\n/**\n * Provides information about how a specific segment of the model's response is supported by the\n * retrieved grounding chunks.\n *\n * @public\n */\nexport interface GroundingSupport {\n  /**\n   * Specifies the segment of the model's response content that this grounding support pertains to.\n   */\n  segment?: Segment;\n  /**\n   * A list of indices that refer to specific {@link GroundingChunk} objects within the\n   * {@link GroundingMetadata.groundingChunks} array. These referenced chunks\n   * are the sources that support the claim made in the associated `segment` of the response.\n   * For example, an array `[1, 3, 4]` means that `groundingChunks[1]`, `groundingChunks[3]`,\n   * and `groundingChunks[4]` are the retrieved content supporting this part of the response.\n   */\n  groundingChunkIndices?: number[];\n}\n\n/**\n * Represents a specific segment within a {@link Content} object, often used to\n * pinpoint the exact location of text or data that grounding information refers to.\n *\n * @public\n */\nexport interface Segment {\n  /**\n   * The zero-based index of the {@link Part} object within the `parts` array\n   * of its parent {@link Content} object. This identifies which part of the\n   * content the segment belongs to.\n   */\n  partIndex: number;\n  /**\n   * The zero-based start index of the segment within the specified `Part`,\n   * measured in UTF-8 bytes. This offset is inclusive, starting from 0 at the\n   * beginning of the part's content (e.g., `Part.text`).\n   */\n  startIndex: number;\n  /**\n   * The zero-based end index of the segment within the specified `Part`,\n   * measured in UTF-8 bytes. This offset is exclusive, meaning the character\n   * at this index is not included in the segment.\n   */\n  endIndex: number;\n  /**\n   * The text corresponding to the segment from the response.\n   */\n  text: string;\n}\n\n/**\n * Metadata related to {@link URLContextTool}.\n *\n * @beta\n */\nexport interface URLContextMetadata {\n  /**\n   * List of URL metadata used to provide context to the Gemini model.\n   */\n  urlMetadata: URLMetadata[];\n}\n\n/**\n * Metadata for a single URL retrieved by the {@link URLContextTool} tool.\n *\n * @beta\n */\nexport interface URLMetadata {\n  /**\n   * The retrieved URL.\n   */\n  retrievedUrl?: string;\n  /**\n   * The status of the URL retrieval.\n   */\n  urlRetrievalStatus?: URLRetrievalStatus;\n}\n\n/**\n * The status of a URL retrieval.\n *\n * @remarks\n * <b>URL_RETRIEVAL_STATUS_UNSPECIFIED:</b> Unspecified retrieval status.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_SUCCESS:</b> The URL retrieval was successful.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_ERROR:</b> The URL retrieval failed.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_PAYWALL:</b> The URL retrieval failed because the content is behind a paywall.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_UNSAFE:</b> The URL retrieval failed because the content is unsafe.\n * <br/>\n *\n * @beta\n */\nexport const URLRetrievalStatus = {\n  /**\n   * Unspecified retrieval status.\n   */\n  URL_RETRIEVAL_STATUS_UNSPECIFIED: 'URL_RETRIEVAL_STATUS_UNSPECIFIED',\n  /**\n   * The URL retrieval was successful.\n   */\n  URL_RETRIEVAL_STATUS_SUCCESS: 'URL_RETRIEVAL_STATUS_SUCCESS',\n  /**\n   * The URL retrieval failed.\n   */\n  URL_RETRIEVAL_STATUS_ERROR: 'URL_RETRIEVAL_STATUS_ERROR',\n  /**\n   * The URL retrieval failed because the content is behind a paywall.\n   */\n  URL_RETRIEVAL_STATUS_PAYWALL: 'URL_RETRIEVAL_STATUS_PAYWALL',\n  /**\n   * The URL retrieval failed because the content is unsafe.\n   */\n  URL_RETRIEVAL_STATUS_UNSAFE: 'URL_RETRIEVAL_STATUS_UNSAFE'\n};\n\n/**\n * The status of a URL retrieval.\n *\n * @remarks\n * <b>URL_RETRIEVAL_STATUS_UNSPECIFIED:</b> Unspecified retrieval status.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_SUCCESS:</b> The URL retrieval was successful.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_ERROR:</b> The URL retrieval failed.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_PAYWALL:</b> The URL retrieval failed because the content is behind a paywall.\n * <br/>\n * <b>URL_RETRIEVAL_STATUS_UNSAFE:</b> The URL retrieval failed because the content is unsafe.\n * <br/>\n *\n * @beta\n */\nexport type URLRetrievalStatus =\n  (typeof URLRetrievalStatus)[keyof typeof URLRetrievalStatus];\n\n/**\n * @public\n */\nexport interface WebAttribution {\n  uri: string;\n  title: string;\n}\n\n/**\n * @public\n */\nexport interface RetrievedContextAttribution {\n  uri: string;\n  title: string;\n}\n\n/**\n * Protobuf google.type.Date\n * @public\n */\nexport interface Date {\n  year: number;\n  month: number;\n  day: number;\n}\n\n/**\n * A safety rating associated with a {@link GenerateContentCandidate}\n * @public\n */\nexport interface SafetyRating {\n  category: HarmCategory;\n  probability: HarmProbability;\n  /**\n   * The harm severity level.\n   *\n   * This property is only supported when using the Vertex AI Gemini API ({@link VertexAIBackend}).\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this property is not supported and will default to `HarmSeverity.UNSUPPORTED`.\n   */\n  severity: HarmSeverity;\n  /**\n   * The probability score of the harm category.\n   *\n   * This property is only supported when using the Vertex AI Gemini API ({@link VertexAIBackend}).\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this property is not supported and will default to 0.\n   */\n  probabilityScore: number;\n  /**\n   * The severity score of the harm category.\n   *\n   * This property is only supported when using the Vertex AI Gemini API ({@link VertexAIBackend}).\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this property is not supported and will default to 0.\n   */\n  severityScore: number;\n  blocked: boolean;\n}\n\n/**\n * Response from calling {@link GenerativeModel.countTokens}.\n * @public\n */\nexport interface CountTokensResponse {\n  /**\n   * The total number of tokens counted across all instances from the request.\n   */\n  totalTokens: number;\n  /**\n   * @deprecated Use `totalTokens` instead. This property is undefined when using models greater than `gemini-1.5-*`.\n   *\n   * The total number of billable characters counted across all instances\n   * from the request.\n   */\n  totalBillableCharacters?: number;\n  /**\n   * The breakdown, by modality, of how many tokens are consumed by the prompt.\n   */\n  promptTokensDetails?: ModalityTokenCount[];\n}\n\n/**\n * An incremental content update from the model.\n *\n * @beta\n */\nexport interface LiveServerContent {\n  type: 'serverContent';\n  /**\n   * The content that the model has generated as part of the current conversation with the user.\n   */\n  modelTurn?: Content;\n  /**\n   * Indicates whether the turn is complete. This is `undefined` if the turn is not complete.\n   */\n  turnComplete?: boolean;\n  /**\n   * Indicates whether the model was interrupted by the client. An interruption occurs when\n   * the client sends a message before the model finishes it's turn. This is `undefined` if the\n   * model was not interrupted.\n   */\n  interrupted?: boolean;\n  /**\n   * Transcription of the audio that was input to the model.\n   */\n  inputTranscription?: Transcription;\n  /**\n   * Transcription of the audio output from the model.\n   */\n  outputTranscription?: Transcription;\n}\n\n/**\n * Transcription of audio. This can be returned from a {@link LiveGenerativeModel} if transcription\n * is enabled with the `inputAudioTranscription` or `outputAudioTranscription` properties on\n * the {@link LiveGenerationConfig}.\n *\n * @beta\n */\n\nexport interface Transcription {\n  /**\n   * The text transcription of the audio.\n   */\n  text?: string;\n}\n\n/**\n * A request from the model for the client to execute one or more functions.\n *\n * @beta\n */\nexport interface LiveServerToolCall {\n  type: 'toolCall';\n  /**\n   * An array of function calls to run.\n   */\n  functionCalls: FunctionCall[];\n}\n\n/**\n * Notification to cancel a previous function call triggered by {@link LiveServerToolCall}.\n *\n * @beta\n */\nexport interface LiveServerToolCallCancellation {\n  type: 'toolCallCancellation';\n  /**\n   * IDs of function calls that were cancelled. These refer to the `id` property of a {@link FunctionCall}.\n   */\n  functionIds: string[];\n}\n\n/**\n * The types of responses that can be returned by {@link LiveSession.receive}.\n *\n * @beta\n */\nexport const LiveResponseType = {\n  SERVER_CONTENT: 'serverContent',\n  TOOL_CALL: 'toolCall',\n  TOOL_CALL_CANCELLATION: 'toolCallCancellation'\n};\n\n/**\n * The types of responses that can be returned by {@link LiveSession.receive}.\n * This is a property on all messages that can be used for type narrowing. This property is not\n * returned by the server, it is assigned to a server message object once it's parsed.\n *\n * @beta\n */\nexport type LiveResponseType =\n  (typeof LiveResponseType)[keyof typeof LiveResponseType];\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { GenerateContentResponse } from './responses';\n\n/**\n * Details object that may be included in an error response.\n *\n * @public\n */\nexport interface ErrorDetails {\n  '@type'?: string;\n\n  /** The reason for the error. */\n  reason?: string;\n\n  /** The domain where the error occurred. */\n  domain?: string;\n\n  /** Additional metadata about the error. */\n  metadata?: Record<string, unknown>;\n\n  /** Any other relevant information about the error. */\n  [key: string]: unknown;\n}\n\n/**\n * Details object that contains data originating from a bad HTTP response.\n *\n * @public\n */\nexport interface CustomErrorData {\n  /** HTTP status code of the error response. */\n  status?: number;\n\n  /** HTTP status text of the error response. */\n  statusText?: string;\n\n  /** Response from a {@link GenerateContentRequest} */\n  response?: GenerateContentResponse;\n\n  /** Optional additional details about the error. */\n  errorDetails?: ErrorDetails[];\n}\n\n/**\n * Standardized error codes that {@link AIError} can have.\n *\n * @public\n */\nexport const AIErrorCode = {\n  /** A generic error occurred. */\n  ERROR: 'error',\n\n  /** An error occurred in a request. */\n  REQUEST_ERROR: 'request-error',\n\n  /** An error occurred in a response. */\n  RESPONSE_ERROR: 'response-error',\n\n  /** An error occurred while performing a fetch. */\n  FETCH_ERROR: 'fetch-error',\n\n  /** An error occurred because an operation was attempted on a closed session. */\n  SESSION_CLOSED: 'session-closed',\n\n  /** An error associated with a Content object.  */\n  INVALID_CONTENT: 'invalid-content',\n\n  /** An error due to the Firebase API not being enabled in the Console. */\n  API_NOT_ENABLED: 'api-not-enabled',\n\n  /** An error due to invalid Schema input.  */\n  INVALID_SCHEMA: 'invalid-schema',\n\n  /** An error occurred due to a missing Firebase API key. */\n  NO_API_KEY: 'no-api-key',\n\n  /** An error occurred due to a missing Firebase app ID. */\n  NO_APP_ID: 'no-app-id',\n\n  /** An error occurred due to a model name not being specified during initialization. */\n  NO_MODEL: 'no-model',\n\n  /** An error occurred due to a missing project ID. */\n  NO_PROJECT_ID: 'no-project-id',\n\n  /** An error occurred while parsing. */\n  PARSE_FAILED: 'parse-failed',\n\n  /** An error occurred due an attempt to use an unsupported feature. */\n  UNSUPPORTED: 'unsupported'\n} as const;\n\n/**\n * Standardized error codes that {@link AIError} can have.\n *\n * @public\n */\nexport type AIErrorCode = (typeof AIErrorCode)[keyof typeof AIErrorCode];\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Contains the list of OpenAPI data types\n * as defined by the\n * {@link https://swagger.io/docs/specification/data-models/data-types/ | OpenAPI specification}\n * @public\n */\nexport const SchemaType = {\n  /** String type. */\n  STRING: 'string',\n  /** Number type. */\n  NUMBER: 'number',\n  /** Integer type. */\n  INTEGER: 'integer',\n  /** Boolean type. */\n  BOOLEAN: 'boolean',\n  /** Array type. */\n  ARRAY: 'array',\n  /** Object type. */\n  OBJECT: 'object'\n} as const;\n\n/**\n * Contains the list of OpenAPI data types\n * as defined by the\n * {@link https://swagger.io/docs/specification/data-models/data-types/ | OpenAPI specification}\n * @public\n */\nexport type SchemaType = (typeof SchemaType)[keyof typeof SchemaType];\n\n/**\n * Basic {@link Schema} properties shared across several Schema-related\n * types.\n * @public\n */\nexport interface SchemaShared<T> {\n  /**\n   * An array of {@link Schema}. The generated data must be valid against any of the schemas\n   * listed in this array. This allows specifying multiple possible structures or types for a\n   * single field.\n   */\n  anyOf?: T[];\n  /** Optional. The format of the property.\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this must be either `'enum'` or\n   * `'date-time'`, otherwise requests will fail.\n   */\n  format?: string;\n  /** Optional. The description of the property. */\n  description?: string;\n  /**\n   * The title of the property. This helps document the schema's purpose but does not typically\n   * constrain the generated value. It can subtly guide the model by clarifying the intent of a\n   * field.\n   */\n  title?: string;\n  /** Optional. The items of the property. */\n  items?: T;\n  /** The minimum number of items (elements) in a schema of {@link (SchemaType:type)} `array`. */\n  minItems?: number;\n  /** The maximum number of items (elements) in a schema of {@link (SchemaType:type)} `array`. */\n  maxItems?: number;\n  /** Optional. Map of `Schema` objects. */\n  properties?: {\n    [k: string]: T;\n  };\n  /** A hint suggesting the order in which the keys should appear in the generated JSON string. */\n  propertyOrdering?: string[];\n  /** Optional. The enum of the property. */\n  enum?: string[];\n  /** Optional. The example of the property. */\n  example?: unknown;\n  /** Optional. Whether the property is nullable. */\n  nullable?: boolean;\n  /** The minimum value of a numeric type. */\n  minimum?: number;\n  /** The maximum value of a numeric type. */\n  maximum?: number;\n  [key: string]: unknown;\n}\n\n/**\n * Params passed to {@link Schema} static methods to create specific\n * {@link Schema} classes.\n * @public\n */\nexport interface SchemaParams extends SchemaShared<SchemaInterface> {}\n\n/**\n * Final format for {@link Schema} params passed to backend requests.\n * @public\n */\nexport interface SchemaRequest extends SchemaShared<SchemaRequest> {\n  /**\n   * The type of the property. this can only be undefined when using `anyOf` schemas,\n   * which do not have an explicit type in the {@link https://swagger.io/docs/specification/v3_0/data-models/data-types/#any-type | OpenAPI specification }.\n   */\n  type?: SchemaType;\n  /** Optional. Array of required property. */\n  required?: string[];\n}\n\n/**\n * Interface for {@link Schema} class.\n * @public\n */\nexport interface SchemaInterface extends SchemaShared<SchemaInterface> {\n  /**\n   * The type of the property. this can only be undefined when using `anyof` schemas,\n   * which do not have an explicit type in the {@link https://swagger.io/docs/specification/v3_0/data-models/data-types/#any-type | OpenAPI Specification}.\n   */\n  type?: SchemaType;\n}\n\n/**\n * Interface for JSON parameters in a schema of {@link (SchemaType:type)}\n * \"object\" when not using the `Schema.object()` helper.\n * @public\n */\nexport interface ObjectSchemaRequest extends SchemaRequest {\n  type: 'object';\n  /**\n   * This is not a property accepted in the final request to the backend, but is\n   * a client-side convenience property that is only usable by constructing\n   * a schema through the `Schema.object()` helper method. Populating this\n   * property will cause response errors if the object is not wrapped with\n   * `Schema.object()`.\n   */\n  optionalProperties?: never;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ImagenImageFormat } from '../../requests/imagen-image-format';\n\n/**\n * Parameters for configuring an {@link ImagenModel}.\n *\n * @public\n */\nexport interface ImagenModelParams {\n  /**\n   * The Imagen model to use for generating images.\n   * For example: `imagen-3.0-generate-002`.\n   *\n   * Only Imagen 3 models (named `imagen-3.0-*`) are supported.\n   *\n   * See {@link https://firebase.google.com/docs/vertex-ai/models | model versions}\n   * for a full list of supported Imagen 3 models.\n   */\n  model: string;\n  /**\n   * Configuration options for generating images with Imagen.\n   */\n  generationConfig?: ImagenGenerationConfig;\n  /**\n   * Safety settings for filtering potentially inappropriate content.\n   */\n  safetySettings?: ImagenSafetySettings;\n}\n\n/**\n * Configuration options for generating images with Imagen.\n *\n * See the {@link http://firebase.google.com/docs/vertex-ai/generate-images-imagen | documentation} for\n * more details.\n *\n * @public\n */\nexport interface ImagenGenerationConfig {\n  /**\n   * A description of what should be omitted from the generated images.\n   *\n   * Support for negative prompts depends on the Imagen model.\n   *\n   * See the {@link http://firebase.google.com/docs/vertex-ai/model-parameters#imagen | documentation} for more details.\n   *\n   * This is no longer supported in the Gemini Developer API ({@link GoogleAIBackend}) in versions\n   * greater than `imagen-3.0-generate-002`.\n   */\n  negativePrompt?: string;\n  /**\n   * The number of images to generate. The default value is 1.\n   *\n   * The number of sample images that may be generated in each request depends on the model\n   * (typically up to 4); see the <a href=\"http://firebase.google.com/docs/vertex-ai/model-parameters#imagen\">sampleCount</a>\n   * documentation for more details.\n   */\n  numberOfImages?: number;\n  /**\n   * The aspect ratio of the generated images. The default value is square 1:1.\n   * Supported aspect ratios depend on the Imagen model, see {@link (ImagenAspectRatio:type)}\n   * for more details.\n   */\n  aspectRatio?: ImagenAspectRatio;\n  /**\n   * The image format of the generated images. The default is PNG.\n   *\n   * See {@link ImagenImageFormat} for more details.\n   */\n  imageFormat?: ImagenImageFormat;\n  /**\n   * Whether to add an invisible watermark to generated images.\n   *\n   * If set to `true`, an invisible SynthID watermark is embedded in generated images to indicate\n   * that they are AI generated. If set to `false`, watermarking will be disabled.\n   *\n   * For Imagen 3 models, the default value is `true`; see the <a href=\"http://firebase.google.com/docs/vertex-ai/model-parameters#imagen\">addWatermark</a>\n   * documentation for more details.\n   *\n   * When using the Gemini Developer API ({@link GoogleAIBackend}), this will default to true,\n   * and cannot be turned off.\n   */\n  addWatermark?: boolean;\n}\n\n/**\n * A filter level controlling how aggressively to filter sensitive content.\n *\n * Text prompts provided as inputs and images (generated or uploaded) through Imagen on Vertex AI\n * are assessed against a list of safety filters, which include 'harmful categories' (for example,\n * `violence`, `sexual`, `derogatory`, and `toxic`). This filter level controls how aggressively to\n * filter out potentially harmful content from responses. See the {@link http://firebase.google.com/docs/vertex-ai/generate-images | documentation }\n * and the {@link https://cloud.google.com/vertex-ai/generative-ai/docs/image/responsible-ai-imagen#safety-filters | Responsible AI and usage guidelines}\n * for more details.\n *\n * @public\n */\nexport const ImagenSafetyFilterLevel = {\n  /**\n   * The most aggressive filtering level; most strict blocking.\n   */\n  BLOCK_LOW_AND_ABOVE: 'block_low_and_above',\n  /**\n   * Blocks some sensitive prompts and responses.\n   */\n  BLOCK_MEDIUM_AND_ABOVE: 'block_medium_and_above',\n  /**\n   * Blocks few sensitive prompts and responses.\n   */\n  BLOCK_ONLY_HIGH: 'block_only_high',\n  /**\n   * The least aggressive filtering level; blocks very few sensitive prompts and responses.\n   *\n   * Access to this feature is restricted and may require your case to be reviewed and approved by\n   * Cloud support.\n   */\n  BLOCK_NONE: 'block_none'\n} as const;\n\n/**\n * A filter level controlling how aggressively to filter sensitive content.\n *\n * Text prompts provided as inputs and images (generated or uploaded) through Imagen on Vertex AI\n * are assessed against a list of safety filters, which include 'harmful categories' (for example,\n * `violence`, `sexual`, `derogatory`, and `toxic`). This filter level controls how aggressively to\n * filter out potentially harmful content from responses. See the {@link http://firebase.google.com/docs/vertex-ai/generate-images | documentation }\n * and the {@link https://cloud.google.com/vertex-ai/generative-ai/docs/image/responsible-ai-imagen#safety-filters | Responsible AI and usage guidelines}\n * for more details.\n *\n * @public\n */\nexport type ImagenSafetyFilterLevel =\n  (typeof ImagenSafetyFilterLevel)[keyof typeof ImagenSafetyFilterLevel];\n\n/**\n * A filter level controlling whether generation of images containing people or faces is allowed.\n *\n * See the <a href=\"http://firebase.google.com/docs/vertex-ai/generate-images\">personGeneration</a>\n * documentation for more details.\n *\n * @public\n */\nexport const ImagenPersonFilterLevel = {\n  /**\n   * Disallow generation of images containing people or faces; images of people are filtered out.\n   */\n  BLOCK_ALL: 'dont_allow',\n  /**\n   * Allow generation of images containing adults only; images of children are filtered out.\n   *\n   * Generation of images containing people or faces may require your use case to be\n   * reviewed and approved by Cloud support; see the {@link https://cloud.google.com/vertex-ai/generative-ai/docs/image/responsible-ai-imagen#person-face-gen | Responsible AI and usage guidelines}\n   * for more details.\n   */\n  ALLOW_ADULT: 'allow_adult',\n  /**\n   * Allow generation of images containing adults only; images of children are filtered out.\n   *\n   * Generation of images containing people or faces may require your use case to be\n   * reviewed and approved by Cloud support; see the {@link https://cloud.google.com/vertex-ai/generative-ai/docs/image/responsible-ai-imagen#person-face-gen | Responsible AI and usage guidelines}\n   * for more details.\n   */\n  ALLOW_ALL: 'allow_all'\n} as const;\n\n/**\n * A filter level controlling whether generation of images containing people or faces is allowed.\n *\n * See the <a href=\"http://firebase.google.com/docs/vertex-ai/generate-images\">personGeneration</a>\n * documentation for more details.\n *\n * @public\n */\nexport type ImagenPersonFilterLevel =\n  (typeof ImagenPersonFilterLevel)[keyof typeof ImagenPersonFilterLevel];\n\n/**\n * Settings for controlling the aggressiveness of filtering out sensitive content.\n *\n * See the {@link http://firebase.google.com/docs/vertex-ai/generate-images | documentation }\n * for more details.\n *\n * @public\n */\nexport interface ImagenSafetySettings {\n  /**\n   * A filter level controlling how aggressive to filter out sensitive content from generated\n   * images.\n   */\n  safetyFilterLevel?: ImagenSafetyFilterLevel;\n  /**\n   * A filter level controlling whether generation of images containing people or faces is allowed.\n   */\n  personFilterLevel?: ImagenPersonFilterLevel;\n}\n\n/**\n * Aspect ratios for Imagen images.\n *\n * To specify an aspect ratio for generated images, set the `aspectRatio` property in your\n * {@link ImagenGenerationConfig}.\n *\n * See the {@link http://firebase.google.com/docs/vertex-ai/generate-images | documentation }\n * for more details and examples of the supported aspect ratios.\n *\n * @public\n */\nexport const ImagenAspectRatio = {\n  /**\n   * Square (1:1) aspect ratio.\n   */\n  'SQUARE': '1:1',\n  /**\n   * Landscape (3:4) aspect ratio.\n   */\n  'LANDSCAPE_3x4': '3:4',\n  /**\n   * Portrait (4:3) aspect ratio.\n   */\n  'PORTRAIT_4x3': '4:3',\n  /**\n   * Landscape (16:9) aspect ratio.\n   */\n  'LANDSCAPE_16x9': '16:9',\n  /**\n   * Portrait (9:16) aspect ratio.\n   */\n  'PORTRAIT_9x16': '9:16'\n} as const;\n\n/**\n * Aspect ratios for Imagen images.\n *\n * To specify an aspect ratio for generated images, set the `aspectRatio` property in your\n * {@link ImagenGenerationConfig}.\n *\n * See the {@link http://firebase.google.com/docs/vertex-ai/generate-images | documentation }\n * for more details and examples of the supported aspect ratios.\n *\n * @public\n */\nexport type ImagenAspectRatio =\n  (typeof ImagenAspectRatio)[keyof typeof ImagenAspectRatio];\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseApp } from '@firebase/app';\nimport { Backend } from './backend';\n\nexport * from './types';\n\n/**\n * An instance of the Firebase AI SDK.\n *\n * Do not create this instance directly. Instead, use {@link getAI | getAI()}.\n *\n * @public\n */\nexport interface AI {\n  /**\n   * The {@link @firebase/app#FirebaseApp} this {@link AI} instance is associated with.\n   */\n  app: FirebaseApp;\n  /**\n   * A {@link Backend} instance that specifies the configuration for the target backend,\n   * either the Gemini Developer API (using {@link GoogleAIBackend}) or the\n   * Vertex AI Gemini API (using {@link VertexAIBackend}).\n   */\n  backend: Backend;\n  /**\n   * Options applied to this {@link AI} instance.\n   */\n  options?: AIOptions;\n  /**\n   * @deprecated use `AI.backend.location` instead.\n   *\n   * The location configured for this AI service instance, relevant for Vertex AI backends.\n   */\n  location: string;\n}\n\n/**\n * An enum-like object containing constants that represent the supported backends\n * for the Firebase AI SDK.\n * This determines which backend service (Vertex AI Gemini API or Gemini Developer API)\n * the SDK will communicate with.\n *\n * These values are assigned to the `backendType` property within the specific backend\n * configuration objects ({@link GoogleAIBackend} or {@link VertexAIBackend}) to identify\n * which service to target.\n *\n * @public\n */\nexport const BackendType = {\n  /**\n   * Identifies the backend service for the Vertex AI Gemini API provided through Google Cloud.\n   * Use this constant when creating a {@link VertexAIBackend} configuration.\n   */\n  VERTEX_AI: 'VERTEX_AI',\n\n  /**\n   * Identifies the backend service for the Gemini Developer API ({@link https://ai.google/ | Google AI}).\n   * Use this constant when creating a {@link GoogleAIBackend} configuration.\n   */\n  GOOGLE_AI: 'GOOGLE_AI'\n} as const; // Using 'as const' makes the string values literal types\n\n/**\n * Type alias representing valid backend types.\n * It can be either `'VERTEX_AI'` or `'GOOGLE_AI'`.\n *\n * @public\n */\nexport type BackendType = (typeof BackendType)[keyof typeof BackendType];\n\n/**\n * Options for initializing the AI service using {@link getAI | getAI()}.\n * This allows specifying which backend to use (Vertex AI Gemini API or Gemini Developer API)\n * and configuring its specific options (like location for Vertex AI).\n *\n * @public\n */\nexport interface AIOptions {\n  /**\n   * The backend configuration to use for the AI service instance.\n   * Defaults to the Gemini Developer API backend ({@link GoogleAIBackend}).\n   */\n  backend?: Backend;\n  /**\n   * Whether to use App Check limited use tokens. Defaults to false.\n   */\n  useLimitedUseAppCheckTokens?: boolean;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DEFAULT_API_VERSION, DEFAULT_LOCATION } from './constants';\nimport { BackendType } from './public-types';\n\n/**\n * Abstract base class representing the configuration for an AI service backend.\n * This class should not be instantiated directly. Use its subclasses; {@link GoogleAIBackend} for\n * the Gemini Developer API (via {@link https://ai.google/ | Google AI}), and\n * {@link VertexAIBackend} for the Vertex AI Gemini API.\n *\n * @public\n */\nexport abstract class Backend {\n  /**\n   * Specifies the backend type.\n   */\n  readonly backendType: BackendType;\n\n  /**\n   * Protected constructor for use by subclasses.\n   * @param type - The backend type.\n   */\n  protected constructor(type: BackendType) {\n    this.backendType = type;\n  }\n\n  /**\n   * @internal\n   */\n  abstract _getModelPath(project: string, model: string): string;\n\n  /**\n   * @internal\n   */\n  abstract _getTemplatePath(project: string, templateId: string): string;\n}\n\n/**\n * Configuration class for the Gemini Developer API.\n *\n * Use this with {@link AIOptions} when initializing the AI service via\n * {@link getAI | getAI()} to specify the Gemini Developer API as the backend.\n *\n * @public\n */\nexport class GoogleAIBackend extends Backend {\n  /**\n   * Creates a configuration object for the Gemini Developer API backend.\n   */\n  constructor() {\n    super(BackendType.GOOGLE_AI);\n  }\n\n  /**\n   * @internal\n   */\n  _getModelPath(project: string, model: string): string {\n    return `/${DEFAULT_API_VERSION}/projects/${project}/${model}`;\n  }\n\n  /**\n   * @internal\n   */\n  _getTemplatePath(project: string, templateId: string): string {\n    return `/${DEFAULT_API_VERSION}/projects/${project}/templates/${templateId}`;\n  }\n}\n\n/**\n * Configuration class for the Vertex AI Gemini API.\n *\n * Use this with {@link AIOptions} when initializing the AI service via\n * {@link getAI | getAI()} to specify the Vertex AI Gemini API as the backend.\n *\n * @public\n */\nexport class VertexAIBackend extends Backend {\n  /**\n   * The region identifier.\n   * See {@link https://firebase.google.com/docs/vertex-ai/locations#available-locations | Vertex AI locations}\n   * for a list of supported locations.\n   */\n  readonly location: string;\n\n  /**\n   * Creates a configuration object for the Vertex AI backend.\n   *\n   * @param location - The region identifier, defaulting to `us-central1`;\n   * see {@link https://firebase.google.com/docs/vertex-ai/locations#available-locations | Vertex AI locations}\n   * for a list of supported locations.\n   */\n  constructor(location: string = DEFAULT_LOCATION) {\n    super(BackendType.VERTEX_AI);\n    if (!location) {\n      this.location = DEFAULT_LOCATION;\n    } else {\n      this.location = location;\n    }\n  }\n\n  /**\n   * @internal\n   */\n  _getModelPath(project: string, model: string): string {\n    return `/${DEFAULT_API_VERSION}/projects/${project}/locations/${this.location}/${model}`;\n  }\n\n  /**\n   * @internal\n   */\n  _getTemplatePath(project: string, templateId: string): string {\n    return `/${DEFAULT_API_VERSION}/projects/${project}/locations/${this.location}/templates/${templateId}`;\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AI_TYPE } from './constants';\nimport { AIError } from './errors';\nimport { AIErrorCode } from './types';\nimport { Backend, GoogleAIBackend, VertexAIBackend } from './backend';\n\n/**\n * Encodes a {@link Backend} into a string that will be used to uniquely identify {@link AI}\n * instances by backend type.\n *\n * @internal\n */\nexport function encodeInstanceIdentifier(backend: Backend): string {\n  if (backend instanceof GoogleAIBackend) {\n    return `${AI_TYPE}/googleai`;\n  } else if (backend instanceof VertexAIBackend) {\n    return `${AI_TYPE}/vertexai/${backend.location}`;\n  } else {\n    throw new AIError(\n      AIErrorCode.ERROR,\n      `Invalid backend: ${JSON.stringify(backend.backendType)}`\n    );\n  }\n}\n\n/**\n * Decodes an instance identifier string into a {@link Backend}.\n *\n * @internal\n */\nexport function decodeInstanceIdentifier(instanceIdentifier: string): Backend {\n  const identifierParts = instanceIdentifier.split('/');\n  if (identifierParts[0] !== AI_TYPE) {\n    throw new AIError(\n      AIErrorCode.ERROR,\n      `Invalid instance identifier, unknown prefix '${identifierParts[0]}'`\n    );\n  }\n  const backendType = identifierParts[1];\n  switch (backendType) {\n    case 'vertexai':\n      const location: string | undefined = identifierParts[2];\n      if (!location) {\n        throw new AIError(\n          AIErrorCode.ERROR,\n          `Invalid instance identifier, unknown location '${instanceIdentifier}'`\n        );\n      }\n      return new VertexAIBackend(location);\n    case 'googleai':\n      return new GoogleAIBackend();\n    default:\n      throw new AIError(\n        AIErrorCode.ERROR,\n        `Invalid instance identifier string: '${instanceIdentifier}'`\n      );\n  }\n}\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseApp, _FirebaseService } from '@firebase/app';\nimport {\n  AI,\n  AIOptions,\n  ChromeAdapter,\n  InferenceMode,\n  OnDeviceParams\n} from './public-types';\nimport {\n  AppCheckInternalComponentName,\n  FirebaseAppCheckInternal\n} from '@firebase/app-check-interop-types';\nimport { Provider } from '@firebase/component';\nimport {\n  FirebaseAuthInternal,\n  FirebaseAuthInternalName\n} from '@firebase/auth-interop-types';\nimport { Backend, VertexAIBackend } from './backend';\n\nexport class AIService implements AI, _FirebaseService {\n  auth: FirebaseAuthInternal | null;\n  appCheck: FirebaseAppCheckInternal | null;\n  _options?: Omit<AIOptions, 'backend'>;\n  location: string; // This is here for backwards-compatibility\n\n  constructor(\n    public app: FirebaseApp,\n    public backend: Backend,\n    authProvider?: Provider<FirebaseAuthInternalName>,\n    appCheckProvider?: Provider<AppCheckInternalComponentName>,\n    public chromeAdapterFactory?: (\n      mode: InferenceMode,\n      window?: Window,\n      params?: OnDeviceParams\n    ) => ChromeAdapter | undefined\n  ) {\n    const appCheck = appCheckProvider?.getImmediate({ optional: true });\n    const auth = authProvider?.getImmediate({ optional: true });\n    this.auth = auth || null;\n    this.appCheck = appCheck || null;\n\n    if (backend instanceof VertexAIBackend) {\n      this.location = backend.location;\n    } else {\n      this.location = '';\n    }\n  }\n\n  _delete(): Promise<void> {\n    return Promise.resolve();\n  }\n\n  set options(optionsToSet: AIOptions) {\n    this._options = optionsToSet;\n  }\n\n  get options(): AIOptions | undefined {\n    return this._options;\n  }\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ComponentContainer,\n  InstanceFactoryOptions\n} from '@firebase/component';\nimport { AIError } from './errors';\nimport { decodeInstanceIdentifier } from './helpers';\nimport { AIService } from './service';\nimport { AIErrorCode } from './types';\n\nexport function factory(\n  container: ComponentContainer,\n  { instanceIdentifier }: InstanceFactoryOptions\n): AIService {\n  if (!instanceIdentifier) {\n    throw new AIError(\n      AIErrorCode.ERROR,\n      'AIService instance identifier is undefined.'\n    );\n  }\n\n  const backend = decodeInstanceIdentifier(instanceIdentifier);\n\n  // getImmediate for FirebaseApp will always succeed\n  const app = container.getProvider('app').getImmediate();\n  const auth = container.getProvider('auth-internal');\n  const appCheckProvider = container.getProvider('app-check-internal');\n\n  return new AIService(app, backend, auth, appCheckProvider);\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { _isFirebaseServerApp } from '@firebase/app';\nimport { AIError } from '../errors';\nimport { AI, AIErrorCode } from '../public-types';\nimport { AIService } from '../service';\nimport { ApiSettings } from '../types/internal';\n\n/**\n * Initializes an {@link ApiSettings} object from an {@link AI} instance.\n *\n * If this is a Server App, the {@link ApiSettings} object's `getAppCheckToken()` will resolve\n * with the `FirebaseServerAppSettings.appCheckToken`, instead of requiring that an App Check\n * instance is initialized.\n */\nexport function initApiSettings(ai: AI): ApiSettings {\n  if (!ai.app?.options?.apiKey) {\n    throw new AIError(\n      AIErrorCode.NO_API_KEY,\n      `The \"apiKey\" field is empty in the local Firebase config. Firebase AI requires this field to contain a valid API key.`\n    );\n  } else if (!ai.app?.options?.projectId) {\n    throw new AIError(\n      AIErrorCode.NO_PROJECT_ID,\n      `The \"projectId\" field is empty in the local Firebase config. Firebase AI requires this field to contain a valid project ID.`\n    );\n  } else if (!ai.app?.options?.appId) {\n    throw new AIError(\n      AIErrorCode.NO_APP_ID,\n      `The \"appId\" field is empty in the local Firebase config. Firebase AI requires this field to contain a valid app ID.`\n    );\n  }\n\n  const apiSettings: ApiSettings = {\n    apiKey: ai.app.options.apiKey,\n    project: ai.app.options.projectId,\n    appId: ai.app.options.appId,\n    automaticDataCollectionEnabled: ai.app.automaticDataCollectionEnabled,\n    location: ai.location,\n    backend: ai.backend\n  };\n\n  if (_isFirebaseServerApp(ai.app) && ai.app.settings.appCheckToken) {\n    const token = ai.app.settings.appCheckToken;\n    apiSettings.getAppCheckToken = () => {\n      return Promise.resolve({ token });\n    };\n  } else if ((ai as AIService).appCheck) {\n    if (ai.options?.useLimitedUseAppCheckTokens) {\n      apiSettings.getAppCheckToken = () =>\n        (ai as AIService).appCheck!.getLimitedUseToken();\n    } else {\n      apiSettings.getAppCheckToken = () =>\n        (ai as AIService).appCheck!.getToken();\n    }\n  }\n\n  if ((ai as AIService).auth) {\n    apiSettings.getAuthToken = () => (ai as AIService).auth!.getToken();\n  }\n\n  return apiSettings;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AI, BackendType } from '../public-types';\nimport { ApiSettings } from '../types/internal';\nimport { initApiSettings } from './utils';\n\n/**\n * Base class for Firebase AI model APIs.\n *\n * Instances of this class are associated with a specific Firebase AI {@link Backend}\n * and provide methods for interacting with the configured generative model.\n *\n * @public\n */\nexport abstract class AIModel {\n  /**\n   * The fully qualified model resource name to use for generating images\n   * (for example, `publishers/google/models/imagen-3.0-generate-002`).\n   */\n  readonly model: string;\n\n  /**\n   * @internal\n   */\n  _apiSettings: ApiSettings;\n\n  /**\n   * Constructs a new instance of the {@link AIModel} class.\n   *\n   * This constructor should only be called from subclasses that provide\n   * a model API.\n   *\n   * @param ai - an {@link AI} instance.\n   * @param modelName - The name of the model being used. It can be in one of the following formats:\n   * - `my-model` (short name, will resolve to `publishers/google/models/my-model`)\n   * - `models/my-model` (will resolve to `publishers/google/models/my-model`)\n   * - `publishers/my-publisher/models/my-model` (fully qualified model name)\n   *\n   * @throws If the `apiKey` or `projectId` fields are missing in your\n   * Firebase config.\n   *\n   * @internal\n   */\n  protected constructor(ai: AI, modelName: string) {\n    this._apiSettings = initApiSettings(ai);\n    this.model = AIModel.normalizeModelName(\n      modelName,\n      this._apiSettings.backend.backendType\n    );\n  }\n\n  /**\n   * Normalizes the given model name to a fully qualified model resource name.\n   *\n   * @param modelName - The model name to normalize.\n   * @returns The fully qualified model resource name.\n   *\n   * @internal\n   */\n  static normalizeModelName(\n    modelName: string,\n    backendType: BackendType\n  ): string {\n    if (backendType === BackendType.GOOGLE_AI) {\n      return AIModel.normalizeGoogleAIModelName(modelName);\n    } else {\n      return AIModel.normalizeVertexAIModelName(modelName);\n    }\n  }\n\n  /**\n   * @internal\n   */\n  private static normalizeGoogleAIModelName(modelName: string): string {\n    return `models/${modelName}`;\n  }\n\n  /**\n   * @internal\n   */\n  private static normalizeVertexAIModelName(modelName: string): string {\n    let model: string;\n    if (modelName.includes('/')) {\n      if (modelName.startsWith('models/')) {\n        // Add 'publishers/google' if the user is only passing in 'models/model-name'.\n        model = `publishers/google/${modelName}`;\n      } else {\n        // Any other custom format (e.g. tuned models) must be passed in correctly.\n        model = modelName;\n      }\n    } else {\n      // If path is not included, assume it's a non-tuned model.\n      model = `publishers/google/models/${modelName}`;\n    }\n\n    return model;\n  }\n}\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger } from '@firebase/logger';\n\nexport const logger = new Logger('@firebase/vertexai');\n","/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ErrorDetails, RequestOptions, AIErrorCode } from '../types';\nimport { AIError } from '../errors';\nimport { ApiSettings } from '../types/internal';\nimport {\n  DEFAULT_DOMAIN,\n  DEFAULT_FETCH_TIMEOUT_MS,\n  LANGUAGE_TAG,\n  PACKAGE_VERSION\n} from '../constants';\nimport { logger } from '../logger';\nimport { BackendType } from '../public-types';\n\nexport const enum Task {\n  GENERATE_CONTENT = 'generateContent',\n  STREAM_GENERATE_CONTENT = 'streamGenerateContent',\n  COUNT_TOKENS = 'countTokens',\n  PREDICT = 'predict'\n}\n\nexport const enum ServerPromptTemplateTask {\n  TEMPLATE_GENERATE_CONTENT = 'templateGenerateContent',\n  TEMPLATE_STREAM_GENERATE_CONTENT = 'templateStreamGenerateContent',\n  TEMPLATE_PREDICT = 'templatePredict'\n}\n\ninterface BaseRequestURLParams {\n  apiSettings: ApiSettings;\n  stream: boolean;\n  requestOptions?: RequestOptions;\n}\n\n/**\n * Parameters used to construct the URL of a request to use a model.\n */\ninterface ModelRequestURLParams extends BaseRequestURLParams {\n  task: Task;\n  model: string;\n  templateId?: never;\n}\n\n/**\n * Parameters used to construct the URL of a request to use server side prompt templates.\n */\ninterface TemplateRequestURLParams extends BaseRequestURLParams {\n  task: ServerPromptTemplateTask;\n  templateId: string;\n  model?: never;\n}\n\nexport class RequestURL {\n  constructor(\n    public readonly params: ModelRequestURLParams | TemplateRequestURLParams\n  ) {}\n\n  toString(): string {\n    const url = new URL(this.baseUrl); // Throws if the URL is invalid\n    url.pathname = this.pathname;\n    url.search = this.queryParams.toString();\n    return url.toString();\n  }\n\n  private get pathname(): string {\n    // We need to construct a different URL if the request is for server side prompt templates,\n    // since the URL patterns are different. Server side prompt templates expect a templateId\n    // instead of a model name.\n    if (this.params.templateId) {\n      return `${this.params.apiSettings.backend._getTemplatePath(\n        this.params.apiSettings.project,\n        this.params.templateId\n      )}:${this.params.task}`;\n    } else {\n      return `${this.params.apiSettings.backend._getModelPath(\n        this.params.apiSettings.project,\n        (this.params as ModelRequestURLParams).model\n      )}:${this.params.task}`;\n    }\n  }\n\n  private get baseUrl(): string {\n    return this.params.requestOptions?.baseUrl ?? `https://${DEFAULT_DOMAIN}`;\n  }\n\n  private get queryParams(): URLSearchParams {\n    const params = new URLSearchParams();\n    if (this.params.stream) {\n      params.set('alt', 'sse');\n    }\n\n    return params;\n  }\n}\n\nexport class WebSocketUrl {\n  constructor(public apiSettings: ApiSettings) {}\n  toString(): string {\n    const url = new URL(`wss://${DEFAULT_DOMAIN}`);\n    url.pathname = this.pathname;\n\n    const queryParams = new URLSearchParams();\n    queryParams.set('key', this.apiSettings.apiKey);\n    url.search = queryParams.toString();\n\n    return url.toString();\n  }\n\n  private get pathname(): string {\n    if (this.apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n      return 'ws/google.firebase.vertexai.v1beta.GenerativeService/BidiGenerateContent';\n    } else {\n      return `ws/google.firebase.vertexai.v1beta.LlmBidiService/BidiGenerateContent/locations/${this.apiSettings.location}`;\n    }\n  }\n}\n\n/**\n * Log language and \"fire/version\" to x-goog-api-client\n */\nfunction getClientHeaders(): string {\n  const loggingTags = [];\n  loggingTags.push(`${LANGUAGE_TAG}/${PACKAGE_VERSION}`);\n  loggingTags.push(`fire/${PACKAGE_VERSION}`);\n  return loggingTags.join(' ');\n}\n\nexport async function getHeaders(url: RequestURL): Promise<Headers> {\n  const headers = new Headers();\n  headers.append('Content-Type', 'application/json');\n  headers.append('x-goog-api-client', getClientHeaders());\n  headers.append('x-goog-api-key', url.params.apiSettings.apiKey);\n  if (url.params.apiSettings.automaticDataCollectionEnabled) {\n    headers.append('X-Firebase-Appid', url.params.apiSettings.appId);\n  }\n  if (url.params.apiSettings.getAppCheckToken) {\n    const appCheckToken = await url.params.apiSettings.getAppCheckToken();\n    if (appCheckToken) {\n      headers.append('X-Firebase-AppCheck', appCheckToken.token);\n      if (appCheckToken.error) {\n        logger.warn(\n          `Unable to obtain a valid App Check token: ${appCheckToken.error.message}`\n        );\n      }\n    }\n  }\n\n  if (url.params.apiSettings.getAuthToken) {\n    const authToken = await url.params.apiSettings.getAuthToken();\n    if (authToken) {\n      headers.append('Authorization', `Firebase ${authToken.accessToken}`);\n    }\n  }\n\n  return headers;\n}\n\nexport async function makeRequest(\n  requestUrlParams: TemplateRequestURLParams | ModelRequestURLParams,\n  body: string\n): Promise<Response> {\n  const url = new RequestURL(requestUrlParams);\n  let response;\n  let fetchTimeoutId: string | number | NodeJS.Timeout | undefined;\n  try {\n    const fetchOptions: RequestInit = {\n      method: 'POST',\n      headers: await getHeaders(url),\n      body\n    };\n\n    // Timeout is 180s by default.\n    const timeoutMillis =\n      requestUrlParams.requestOptions?.timeout != null &&\n      requestUrlParams.requestOptions.timeout >= 0\n        ? requestUrlParams.requestOptions.timeout\n        : DEFAULT_FETCH_TIMEOUT_MS;\n    const abortController = new AbortController();\n    fetchTimeoutId = setTimeout(() => abortController.abort(), timeoutMillis);\n    fetchOptions.signal = abortController.signal;\n\n    response = await fetch(url.toString(), fetchOptions);\n    if (!response.ok) {\n      let message = '';\n      let errorDetails;\n      try {\n        const json = await response.json();\n        message = json.error.message;\n        if (json.error.details) {\n          message += ` ${JSON.stringify(json.error.details)}`;\n          errorDetails = json.error.details;\n        }\n      } catch (e) {\n        // ignored\n      }\n      if (\n        response.status === 403 &&\n        errorDetails &&\n        errorDetails.some(\n          (detail: ErrorDetails) => detail.reason === 'SERVICE_DISABLED'\n        ) &&\n        errorDetails.some((detail: ErrorDetails) =>\n          (\n            detail.links as Array<Record<string, string>>\n          )?.[0]?.description.includes(\n            'Google developers console API activation'\n          )\n        )\n      ) {\n        throw new AIError(\n          AIErrorCode.API_NOT_ENABLED,\n          `The Firebase AI SDK requires the Firebase AI ` +\n            `API ('firebasevertexai.googleapis.com') to be enabled in your ` +\n            `Firebase project. Enable this API by visiting the Firebase Console ` +\n            `at https://console.firebase.google.com/project/${url.params.apiSettings.project}/ailogic/ ` +\n            `and clicking \"Get started\". If you enabled this API recently, ` +\n            `wait a few minutes for the action to propagate to our systems and ` +\n            `then retry.`,\n          {\n            status: response.status,\n            statusText: response.statusText,\n            errorDetails\n          }\n        );\n      }\n      throw new AIError(\n        AIErrorCode.FETCH_ERROR,\n        `Error fetching from ${url}: [${response.status} ${response.statusText}] ${message}`,\n        {\n          status: response.status,\n          statusText: response.statusText,\n          errorDetails\n        }\n      );\n    }\n  } catch (e) {\n    let err = e as Error;\n    if (\n      (e as AIError).code !== AIErrorCode.FETCH_ERROR &&\n      (e as AIError).code !== AIErrorCode.API_NOT_ENABLED &&\n      e instanceof Error\n    ) {\n      err = new AIError(\n        AIErrorCode.ERROR,\n        `Error fetching from ${url.toString()}: ${e.message}`\n      );\n      err.stack = e.stack;\n    }\n\n    throw err;\n  } finally {\n    if (fetchTimeoutId) {\n      clearTimeout(fetchTimeoutId);\n    }\n  }\n  return response;\n}\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  EnhancedGenerateContentResponse,\n  FinishReason,\n  FunctionCall,\n  GenerateContentCandidate,\n  GenerateContentResponse,\n  ImagenGCSImage,\n  ImagenInlineImage,\n  AIErrorCode,\n  InlineDataPart,\n  Part,\n  InferenceSource\n} from '../types';\nimport { AIError } from '../errors';\nimport { logger } from '../logger';\nimport { ImagenResponseInternal } from '../types/internal';\n\n/**\n * Check that at least one candidate exists and does not have a bad\n * finish reason. Warns if multiple candidates exist.\n */\nfunction hasValidCandidates(response: GenerateContentResponse): boolean {\n  if (response.candidates && response.candidates.length > 0) {\n    if (response.candidates.length > 1) {\n      logger.warn(\n        `This response had ${response.candidates.length} ` +\n          `candidates. Returning text from the first candidate only. ` +\n          `Access response.candidates directly to use the other candidates.`\n      );\n    }\n    if (hadBadFinishReason(response.candidates[0])) {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Response error: ${formatBlockErrorMessage(\n          response\n        )}. Response body stored in error.response`,\n        {\n          response\n        }\n      );\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\n\n/**\n * Creates an EnhancedGenerateContentResponse object that has helper functions and\n * other modifications that improve usability.\n */\nexport function createEnhancedContentResponse(\n  response: GenerateContentResponse,\n  inferenceSource: InferenceSource = InferenceSource.IN_CLOUD\n): EnhancedGenerateContentResponse {\n  /**\n   * The Vertex AI backend omits default values.\n   * This causes the `index` property to be omitted from the first candidate in the\n   * response, since it has index 0, and 0 is a default value.\n   * See: https://github.com/firebase/firebase-js-sdk/issues/8566\n   */\n  if (response.candidates && !response.candidates[0].hasOwnProperty('index')) {\n    response.candidates[0].index = 0;\n  }\n\n  const responseWithHelpers = addHelpers(response);\n  responseWithHelpers.inferenceSource = inferenceSource;\n  return responseWithHelpers;\n}\n\n/**\n * Adds convenience helper methods to a response object, including stream\n * chunks (as long as each chunk is a complete GenerateContentResponse JSON).\n */\nexport function addHelpers(\n  response: GenerateContentResponse\n): EnhancedGenerateContentResponse {\n  (response as EnhancedGenerateContentResponse).text = () => {\n    if (hasValidCandidates(response)) {\n      return getText(response, part => !part.thought);\n    } else if (response.promptFeedback) {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Text not available. ${formatBlockErrorMessage(response)}`,\n        {\n          response\n        }\n      );\n    }\n    return '';\n  };\n  (response as EnhancedGenerateContentResponse).thoughtSummary = () => {\n    if (hasValidCandidates(response)) {\n      const result = getText(response, part => !!part.thought);\n      return result === '' ? undefined : result;\n    } else if (response.promptFeedback) {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Thought summary not available. ${formatBlockErrorMessage(response)}`,\n        {\n          response\n        }\n      );\n    }\n    return undefined;\n  };\n  (response as EnhancedGenerateContentResponse).inlineDataParts = ():\n    | InlineDataPart[]\n    | undefined => {\n    if (hasValidCandidates(response)) {\n      return getInlineDataParts(response);\n    } else if (response.promptFeedback) {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Data not available. ${formatBlockErrorMessage(response)}`,\n        {\n          response\n        }\n      );\n    }\n    return undefined;\n  };\n  (response as EnhancedGenerateContentResponse).functionCalls = () => {\n    if (hasValidCandidates(response)) {\n      return getFunctionCalls(response);\n    } else if (response.promptFeedback) {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Function call not available. ${formatBlockErrorMessage(response)}`,\n        {\n          response\n        }\n      );\n    }\n    return undefined;\n  };\n  return response as EnhancedGenerateContentResponse;\n}\n\n/**\n * Returns all text from the first candidate's parts, filtering by whether\n * `partFilter()` returns true.\n *\n * @param response - The `GenerateContentResponse` from which to extract text.\n * @param partFilter - Only return `Part`s for which this returns true\n */\nexport function getText(\n  response: GenerateContentResponse,\n  partFilter: (part: Part) => boolean\n): string {\n  const textStrings = [];\n  if (response.candidates?.[0].content?.parts) {\n    for (const part of response.candidates?.[0].content?.parts) {\n      if (part.text && partFilter(part)) {\n        textStrings.push(part.text);\n      }\n    }\n  }\n  if (textStrings.length > 0) {\n    return textStrings.join('');\n  } else {\n    return '';\n  }\n}\n\n/**\n * Returns every {@link FunctionCall} associated with first candidate.\n */\nexport function getFunctionCalls(\n  response: GenerateContentResponse\n): FunctionCall[] | undefined {\n  const functionCalls: FunctionCall[] = [];\n  if (response.candidates?.[0].content?.parts) {\n    for (const part of response.candidates?.[0].content?.parts) {\n      if (part.functionCall) {\n        functionCalls.push(part.functionCall);\n      }\n    }\n  }\n  if (functionCalls.length > 0) {\n    return functionCalls;\n  } else {\n    return undefined;\n  }\n}\n\n/**\n * Returns every {@link InlineDataPart} in the first candidate if present.\n *\n * @internal\n */\nexport function getInlineDataParts(\n  response: GenerateContentResponse\n): InlineDataPart[] | undefined {\n  const data: InlineDataPart[] = [];\n\n  if (response.candidates?.[0].content?.parts) {\n    for (const part of response.candidates?.[0].content?.parts) {\n      if (part.inlineData) {\n        data.push(part);\n      }\n    }\n  }\n\n  if (data.length > 0) {\n    return data;\n  } else {\n    return undefined;\n  }\n}\n\nconst badFinishReasons = [FinishReason.RECITATION, FinishReason.SAFETY];\n\nfunction hadBadFinishReason(candidate: GenerateContentCandidate): boolean {\n  return (\n    !!candidate.finishReason &&\n    badFinishReasons.some(reason => reason === candidate.finishReason)\n  );\n}\n\nexport function formatBlockErrorMessage(\n  response: GenerateContentResponse\n): string {\n  let message = '';\n  if (\n    (!response.candidates || response.candidates.length === 0) &&\n    response.promptFeedback\n  ) {\n    message += 'Response was blocked';\n    if (response.promptFeedback?.blockReason) {\n      message += ` due to ${response.promptFeedback.blockReason}`;\n    }\n    if (response.promptFeedback?.blockReasonMessage) {\n      message += `: ${response.promptFeedback.blockReasonMessage}`;\n    }\n  } else if (response.candidates?.[0]) {\n    const firstCandidate = response.candidates[0];\n    if (hadBadFinishReason(firstCandidate)) {\n      message += `Candidate was blocked due to ${firstCandidate.finishReason}`;\n      if (firstCandidate.finishMessage) {\n        message += `: ${firstCandidate.finishMessage}`;\n      }\n    }\n  }\n  return message;\n}\n\n/**\n * Convert a generic successful fetch response body to an Imagen response object\n * that can be returned to the user. This converts the REST APIs response format to our\n * APIs representation of a response.\n *\n * @internal\n */\nexport async function handlePredictResponse<\n  T extends ImagenInlineImage | ImagenGCSImage\n>(response: Response): Promise<{ images: T[]; filteredReason?: string }> {\n  const responseJson: ImagenResponseInternal = await response.json();\n\n  const images: T[] = [];\n  let filteredReason: string | undefined = undefined;\n\n  // The backend should always send a non-empty array of predictions if the response was successful.\n  if (!responseJson.predictions || responseJson.predictions?.length === 0) {\n    throw new AIError(\n      AIErrorCode.RESPONSE_ERROR,\n      'No predictions or filtered reason received from Vertex AI. Please report this issue with the full error details at https://github.com/firebase/firebase-js-sdk/issues.'\n    );\n  }\n\n  for (const prediction of responseJson.predictions) {\n    if (prediction.raiFilteredReason) {\n      filteredReason = prediction.raiFilteredReason;\n    } else if (prediction.mimeType && prediction.bytesBase64Encoded) {\n      images.push({\n        mimeType: prediction.mimeType,\n        bytesBase64Encoded: prediction.bytesBase64Encoded\n      } as T);\n    } else if (prediction.mimeType && prediction.gcsUri) {\n      images.push({\n        mimeType: prediction.mimeType,\n        gcsURI: prediction.gcsUri\n      } as T);\n    } else if (prediction.safetyAttributes) {\n      // Ignore safetyAttributes \"prediction\" to avoid throwing an error below.\n    } else {\n      throw new AIError(\n        AIErrorCode.RESPONSE_ERROR,\n        `Unexpected element in 'predictions' array in response: '${JSON.stringify(\n          prediction\n        )}'`\n      );\n    }\n  }\n\n  return { images, filteredReason };\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AIError } from './errors';\nimport { logger } from './logger';\nimport {\n  CitationMetadata,\n  CountTokensRequest,\n  GenerateContentCandidate,\n  GenerateContentRequest,\n  GenerateContentResponse,\n  HarmSeverity,\n  InlineDataPart,\n  PromptFeedback,\n  SafetyRating,\n  AIErrorCode\n} from './types';\nimport {\n  GoogleAIGenerateContentResponse,\n  GoogleAIGenerateContentCandidate,\n  GoogleAICountTokensRequest\n} from './types/googleai';\n\n/**\n * This SDK supports both the Vertex AI Gemini API and the Gemini Developer API (using Google AI).\n * The public API prioritizes the format used by the Vertex AI Gemini API.\n * We avoid having two sets of types by translating requests and responses between the two API formats.\n * This translation allows developers to switch between the Vertex AI Gemini API and the Gemini Developer API\n * with minimal code changes.\n *\n * In here are functions that map requests and responses between the two API formats.\n * Requests in the Vertex AI format are mapped to the Google AI format before being sent.\n * Responses from the Google AI backend are mapped back to the Vertex AI format before being returned to the user.\n */\n\n/**\n * Maps a Vertex AI {@link GenerateContentRequest} to a format that can be sent to Google AI.\n *\n * @param generateContentRequest The {@link GenerateContentRequest} to map.\n * @returns A {@link GenerateContentResponse} that conforms to the Google AI format.\n *\n * @throws If the request contains properties that are unsupported by Google AI.\n *\n * @internal\n */\nexport function mapGenerateContentRequest(\n  generateContentRequest: GenerateContentRequest\n): GenerateContentRequest {\n  generateContentRequest.safetySettings?.forEach(safetySetting => {\n    if (safetySetting.method) {\n      throw new AIError(\n        AIErrorCode.UNSUPPORTED,\n        'SafetySetting.method is not supported in the the Gemini Developer API. Please remove this property.'\n      );\n    }\n  });\n\n  if (generateContentRequest.generationConfig?.topK) {\n    const roundedTopK = Math.round(\n      generateContentRequest.generationConfig.topK\n    );\n\n    if (roundedTopK !== generateContentRequest.generationConfig.topK) {\n      logger.warn(\n        'topK in GenerationConfig has been rounded to the nearest integer to match the format for requests to the Gemini Developer API.'\n      );\n      generateContentRequest.generationConfig.topK = roundedTopK;\n    }\n  }\n\n  return generateContentRequest;\n}\n\n/**\n * Maps a {@link GenerateContentResponse} from Google AI to the format of the\n * {@link GenerateContentResponse} that we get from VertexAI that is exposed in the public API.\n *\n * @param googleAIResponse The {@link GenerateContentResponse} from Google AI.\n * @returns A {@link GenerateContentResponse} that conforms to the public API's format.\n *\n * @internal\n */\nexport function mapGenerateContentResponse(\n  googleAIResponse: GoogleAIGenerateContentResponse\n): GenerateContentResponse {\n  const generateContentResponse = {\n    candidates: googleAIResponse.candidates\n      ? mapGenerateContentCandidates(googleAIResponse.candidates)\n      : undefined,\n    prompt: googleAIResponse.promptFeedback\n      ? mapPromptFeedback(googleAIResponse.promptFeedback)\n      : undefined,\n    usageMetadata: googleAIResponse.usageMetadata\n  };\n\n  return generateContentResponse;\n}\n\n/**\n * Maps a Vertex AI {@link CountTokensRequest} to a format that can be sent to Google AI.\n *\n * @param countTokensRequest The {@link CountTokensRequest} to map.\n * @param model The model to count tokens with.\n * @returns A {@link CountTokensRequest} that conforms to the Google AI format.\n *\n * @internal\n */\nexport function mapCountTokensRequest(\n  countTokensRequest: CountTokensRequest,\n  model: string\n): GoogleAICountTokensRequest {\n  const mappedCountTokensRequest: GoogleAICountTokensRequest = {\n    generateContentRequest: {\n      model,\n      ...countTokensRequest\n    }\n  };\n\n  return mappedCountTokensRequest;\n}\n\n/**\n * Maps a Google AI {@link GoogleAIGenerateContentCandidate} to a format that conforms\n * to the Vertex AI API format.\n *\n * @param candidates The {@link GoogleAIGenerateContentCandidate} to map.\n * @returns A {@link GenerateContentCandidate} that conforms to the Vertex AI format.\n *\n * @throws If any {@link Part} in the candidates has a `videoMetadata` property.\n *\n * @internal\n */\nexport function mapGenerateContentCandidates(\n  candidates: GoogleAIGenerateContentCandidate[]\n): GenerateContentCandidate[] {\n  const mappedCandidates: GenerateContentCandidate[] = [];\n  let mappedSafetyRatings: SafetyRating[];\n  if (mappedCandidates) {\n    candidates.forEach(candidate => {\n      // Map citationSources to citations.\n      let citationMetadata: CitationMetadata | undefined;\n      if (candidate.citationMetadata) {\n        citationMetadata = {\n          citations: candidate.citationMetadata.citationSources\n        };\n      }\n\n      // Assign missing candidate SafetyRatings properties to their defaults if undefined.\n      if (candidate.safetyRatings) {\n        mappedSafetyRatings = candidate.safetyRatings.map(safetyRating => {\n          return {\n            ...safetyRating,\n            severity:\n              safetyRating.severity ?? HarmSeverity.HARM_SEVERITY_UNSUPPORTED,\n            probabilityScore: safetyRating.probabilityScore ?? 0,\n            severityScore: safetyRating.severityScore ?? 0\n          };\n        });\n      }\n\n      // videoMetadata is not supported.\n      // Throw early since developers may send a long video as input and only expect to pay\n      // for inference on a small portion of the video.\n      if (\n        candidate.content?.parts?.some(\n          part => (part as InlineDataPart)?.videoMetadata\n        )\n      ) {\n        throw new AIError(\n          AIErrorCode.UNSUPPORTED,\n          'Part.videoMetadata is not supported in the Gemini Developer API. Please remove this property.'\n        );\n      }\n\n      const mappedCandidate = {\n        index: candidate.index,\n        content: candidate.content,\n        finishReason: candidate.finishReason,\n        finishMessage: candidate.finishMessage,\n        safetyRatings: mappedSafetyRatings,\n        citationMetadata,\n        groundingMetadata: candidate.groundingMetadata,\n        urlContextMetadata: candidate.urlContextMetadata\n      };\n      mappedCandidates.push(mappedCandidate);\n    });\n  }\n\n  return mappedCandidates;\n}\n\nexport function mapPromptFeedback(\n  promptFeedback: PromptFeedback\n): PromptFeedback {\n  // Assign missing SafetyRating properties to their defaults if undefined.\n  const mappedSafetyRatings: SafetyRating[] = [];\n  promptFeedback.safetyRatings.forEach(safetyRating => {\n    mappedSafetyRatings.push({\n      category: safetyRating.category,\n      probability: safetyRating.probability,\n      severity: safetyRating.severity ?? HarmSeverity.HARM_SEVERITY_UNSUPPORTED,\n      probabilityScore: safetyRating.probabilityScore ?? 0,\n      severityScore: safetyRating.severityScore ?? 0,\n      blocked: safetyRating.blocked\n    });\n  });\n\n  const mappedPromptFeedback: PromptFeedback = {\n    blockReason: promptFeedback.blockReason,\n    safetyRatings: mappedSafetyRatings,\n    blockReasonMessage: promptFeedback.blockReasonMessage\n  };\n  return mappedPromptFeedback;\n}\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  EnhancedGenerateContentResponse,\n  GenerateContentCandidate,\n  GenerateContentResponse,\n  GenerateContentStreamResult,\n  Part,\n  AIErrorCode\n} from '../types';\nimport { AIError } from '../errors';\nimport { createEnhancedContentResponse } from './response-helpers';\nimport * as GoogleAIMapper from '../googleai-mappers';\nimport { GoogleAIGenerateContentResponse } from '../types/googleai';\nimport { ApiSettings } from '../types/internal';\nimport {\n  BackendType,\n  InferenceSource,\n  URLContextMetadata\n} from '../public-types';\n\nconst responseLineRE = /^data\\: (.*)(?:\\n\\n|\\r\\r|\\r\\n\\r\\n)/;\n\n/**\n * Process a response.body stream from the backend and return an\n * iterator that provides one complete GenerateContentResponse at a time\n * and a promise that resolves with a single aggregated\n * GenerateContentResponse.\n *\n * @param response - Response from a fetch call\n */\nexport function processStream(\n  response: Response,\n  apiSettings: ApiSettings,\n  inferenceSource?: InferenceSource\n): GenerateContentStreamResult {\n  const inputStream = response.body!.pipeThrough(\n    new TextDecoderStream('utf8', { fatal: true })\n  );\n  const responseStream =\n    getResponseStream<GenerateContentResponse>(inputStream);\n  const [stream1, stream2] = responseStream.tee();\n  return {\n    stream: generateResponseSequence(stream1, apiSettings, inferenceSource),\n    response: getResponsePromise(stream2, apiSettings, inferenceSource)\n  };\n}\n\nasync function getResponsePromise(\n  stream: ReadableStream<GenerateContentResponse>,\n  apiSettings: ApiSettings,\n  inferenceSource?: InferenceSource\n): Promise<EnhancedGenerateContentResponse> {\n  const allResponses: GenerateContentResponse[] = [];\n  const reader = stream.getReader();\n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) {\n      let generateContentResponse = aggregateResponses(allResponses);\n      if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n        generateContentResponse = GoogleAIMapper.mapGenerateContentResponse(\n          generateContentResponse as GoogleAIGenerateContentResponse\n        );\n      }\n      return createEnhancedContentResponse(\n        generateContentResponse,\n        inferenceSource\n      );\n    }\n\n    allResponses.push(value);\n  }\n}\n\nasync function* generateResponseSequence(\n  stream: ReadableStream<GenerateContentResponse>,\n  apiSettings: ApiSettings,\n  inferenceSource?: InferenceSource\n): AsyncGenerator<EnhancedGenerateContentResponse> {\n  const reader = stream.getReader();\n  while (true) {\n    const { value, done } = await reader.read();\n    if (done) {\n      break;\n    }\n\n    let enhancedResponse: EnhancedGenerateContentResponse;\n    if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n      enhancedResponse = createEnhancedContentResponse(\n        GoogleAIMapper.mapGenerateContentResponse(\n          value as GoogleAIGenerateContentResponse\n        ),\n        inferenceSource\n      );\n    } else {\n      enhancedResponse = createEnhancedContentResponse(value, inferenceSource);\n    }\n\n    const firstCandidate = enhancedResponse.candidates?.[0];\n    // Don't yield a response with no useful data for the developer.\n    if (\n      !firstCandidate?.content?.parts &&\n      !firstCandidate?.finishReason &&\n      !firstCandidate?.citationMetadata &&\n      !firstCandidate?.urlContextMetadata\n    ) {\n      continue;\n    }\n\n    yield enhancedResponse;\n  }\n}\n\n/**\n * Reads a raw stream from the fetch response and join incomplete\n * chunks, returning a new stream that provides a single complete\n * GenerateContentResponse in each iteration.\n */\nexport function getResponseStream<T>(\n  inputStream: ReadableStream<string>\n): ReadableStream<T> {\n  const reader = inputStream.getReader();\n  const stream = new ReadableStream<T>({\n    start(controller) {\n      let currentText = '';\n      return pump();\n      function pump(): Promise<(() => Promise<void>) | undefined> {\n        return reader.read().then(({ value, done }) => {\n          if (done) {\n            if (currentText.trim()) {\n              controller.error(\n                new AIError(AIErrorCode.PARSE_FAILED, 'Failed to parse stream')\n              );\n              return;\n            }\n            controller.close();\n            return;\n          }\n\n          currentText += value;\n          let match = currentText.match(responseLineRE);\n          let parsedResponse: T;\n          while (match) {\n            try {\n              parsedResponse = JSON.parse(match[1]);\n            } catch (e) {\n              controller.error(\n                new AIError(\n                  AIErrorCode.PARSE_FAILED,\n                  `Error parsing JSON response: \"${match[1]}`\n                )\n              );\n              return;\n            }\n            controller.enqueue(parsedResponse);\n            currentText = currentText.substring(match[0].length);\n            match = currentText.match(responseLineRE);\n          }\n          return pump();\n        });\n      }\n    }\n  });\n  return stream;\n}\n\n/**\n * Aggregates an array of `GenerateContentResponse`s into a single\n * GenerateContentResponse.\n */\nexport function aggregateResponses(\n  responses: GenerateContentResponse[]\n): GenerateContentResponse {\n  const lastResponse = responses[responses.length - 1];\n  const aggregatedResponse: GenerateContentResponse = {\n    promptFeedback: lastResponse?.promptFeedback\n  };\n  for (const response of responses) {\n    if (response.candidates) {\n      for (const candidate of response.candidates) {\n        // Index will be undefined if it's the first index (0), so we should use 0 if it's undefined.\n        // See: https://github.com/firebase/firebase-js-sdk/issues/8566\n        const i = candidate.index || 0;\n        if (!aggregatedResponse.candidates) {\n          aggregatedResponse.candidates = [];\n        }\n        if (!aggregatedResponse.candidates[i]) {\n          aggregatedResponse.candidates[i] = {\n            index: candidate.index\n          } as GenerateContentCandidate;\n        }\n        // Keep overwriting, the last one will be final\n        aggregatedResponse.candidates[i].citationMetadata =\n          candidate.citationMetadata;\n        aggregatedResponse.candidates[i].finishReason = candidate.finishReason;\n        aggregatedResponse.candidates[i].finishMessage =\n          candidate.finishMessage;\n        aggregatedResponse.candidates[i].safetyRatings =\n          candidate.safetyRatings;\n        aggregatedResponse.candidates[i].groundingMetadata =\n          candidate.groundingMetadata;\n\n        // The urlContextMetadata object is defined in the first chunk of the response stream.\n        // In all subsequent chunks, the urlContextMetadata object will be undefined. We need to\n        // make sure that we don't overwrite the first value urlContextMetadata object with undefined.\n        // FIXME: What happens if we receive a second, valid urlContextMetadata object?\n        const urlContextMetadata = candidate.urlContextMetadata as unknown;\n        if (\n          typeof urlContextMetadata === 'object' &&\n          urlContextMetadata !== null &&\n          Object.keys(urlContextMetadata).length > 0\n        ) {\n          aggregatedResponse.candidates[i].urlContextMetadata =\n            urlContextMetadata as URLContextMetadata;\n        }\n\n        /**\n         * Candidates should always have content and parts, but this handles\n         * possible malformed responses.\n         */\n        if (candidate.content) {\n          // Skip a candidate without parts.\n          if (!candidate.content.parts) {\n            continue;\n          }\n          if (!aggregatedResponse.candidates[i].content) {\n            aggregatedResponse.candidates[i].content = {\n              role: candidate.content.role || 'user',\n              parts: []\n            };\n          }\n          for (const part of candidate.content.parts) {\n            const newPart: Part = { ...part };\n            // The backend can send empty text parts. If these are sent back\n            // (e.g. in chat history), the backend will respond with an error.\n            // To prevent this, ignore empty text parts.\n            if (part.text === '') {\n              continue;\n            }\n            if (Object.keys(newPart).length > 0) {\n              aggregatedResponse.candidates[i].content.parts.push(\n                newPart as Part\n              );\n            }\n          }\n        }\n      }\n    }\n  }\n  return aggregatedResponse;\n}\n","/**\n * @license\n * Copyright 2025 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AIError } from '../errors';\nimport {\n  GenerateContentRequest,\n  InferenceMode,\n  AIErrorCode,\n  ChromeAdapter,\n  InferenceSource\n} from '../types';\n\nconst errorsCausingFallback: AIErrorCode[] = [\n  // most network errors\n  AIErrorCode.FETCH_ERROR,\n  // fallback code for all other errors in makeRequest\n  AIErrorCode.ERROR,\n  // error due to API not being enabled in project\n  AIErrorCode.API_NOT_ENABLED\n];\n\ninterface CallResult<Response> {\n  response: Response;\n  inferenceSource: InferenceSource;\n}\n\n/**\n * Dispatches a request to the appropriate backend (on-device or in-cloud)\n * based on the inference mode.\n *\n * @param request - The request to be sent.\n * @param chromeAdapter - The on-device model adapter.\n * @param onDeviceCall - The function to call for on-device inference.\n * @param inCloudCall - The function to call for in-cloud inference.\n * @returns The response from the backend.\n */\nexport async function callCloudOrDevice<Response>(\n  request: GenerateContentRequest,\n  chromeAdapter: ChromeAdapter | undefined,\n  onDeviceCall: () => Promise<Response>,\n  inCloudCall: () => Promise<Response>\n): Promise<CallResult<Response>> {\n  if (!chromeAdapter) {\n    return {\n      response: await inCloudCall(),\n      inferenceSource: InferenceSource.IN_CLOUD\n    };\n  }\n  switch (chromeAdapter.mode) {\n    case InferenceMode.ONLY_ON_DEVICE:\n      if (await chromeAdapter.isAvailable(request)) {\n        return {\n          response: await onDeviceCall(),\n          inferenceSource: InferenceSource.ON_DEVICE\n        };\n      }\n      throw new AIError(\n        AIErrorCode.UNSUPPORTED,\n        'Inference mode is ONLY_ON_DEVICE, but an on-device model is not available.'\n      );\n    case InferenceMode.ONLY_IN_CLOUD:\n      return {\n        response: await inCloudCall(),\n        inferenceSource: InferenceSource.IN_CLOUD\n      };\n    case InferenceMode.PREFER_IN_CLOUD:\n      try {\n        return {\n          response: await inCloudCall(),\n          inferenceSource: InferenceSource.IN_CLOUD\n        };\n      } catch (e) {\n        if (e instanceof AIError && errorsCausingFallback.includes(e.code)) {\n          return {\n            response: await onDeviceCall(),\n            inferenceSource: InferenceSource.ON_DEVICE\n          };\n        }\n        throw e;\n      }\n    case InferenceMode.PREFER_ON_DEVICE:\n      if (await chromeAdapter.isAvailable(request)) {\n        return {\n          response: await onDeviceCall(),\n          inferenceSource: InferenceSource.ON_DEVICE\n        };\n      }\n      return {\n        response: await inCloudCall(),\n        inferenceSource: InferenceSource.IN_CLOUD\n      };\n    default:\n      throw new AIError(\n        AIErrorCode.ERROR,\n        `Unexpected infererence mode: ${chromeAdapter.mode}`\n      );\n  }\n}\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  GenerateContentRequest,\n  GenerateContentResponse,\n  GenerateContentResult,\n  GenerateContentStreamResult,\n  RequestOptions\n} from '../types';\nimport {\n  makeRequest,\n  ServerPromptTemplateTask,\n  Task\n} from '../requests/request';\nimport { createEnhancedContentResponse } from '../requests/response-helpers';\nimport { processStream } from '../requests/stream-reader';\nimport { ApiSettings } from '../types/internal';\nimport * as GoogleAIMapper from '../googleai-mappers';\nimport { BackendType } from '../public-types';\nimport { ChromeAdapter } from '../types/chrome-adapter';\nimport { callCloudOrDevice } from '../requests/hybrid-helpers';\n\nasync function generateContentStreamOnCloud(\n  apiSettings: ApiSettings,\n  model: string,\n  params: GenerateContentRequest,\n  requestOptions?: RequestOptions\n): Promise<Response> {\n  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n    params = GoogleAIMapper.mapGenerateContentRequest(params);\n  }\n  return makeRequest(\n    {\n      task: Task.STREAM_GENERATE_CONTENT,\n      model,\n      apiSettings,\n      stream: true,\n      requestOptions\n    },\n    JSON.stringify(params)\n  );\n}\n\nexport async function generateContentStream(\n  apiSettings: ApiSettings,\n  model: string,\n  params: GenerateContentRequest,\n  chromeAdapter?: ChromeAdapter,\n  requestOptions?: RequestOptions\n): Promise<GenerateContentStreamResult> {\n  const callResult = await callCloudOrDevice(\n    params,\n    chromeAdapter,\n    () => chromeAdapter!.generateContentStream(params),\n    () =>\n      generateContentStreamOnCloud(apiSettings, model, params, requestOptions)\n  );\n  return processStream(\n    callResult.response,\n    apiSettings,\n    callResult.inferenceSource\n  );\n}\n\nasync function generateContentOnCloud(\n  apiSettings: ApiSettings,\n  model: string,\n  params: GenerateContentRequest,\n  requestOptions?: RequestOptions\n): Promise<Response> {\n  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n    params = GoogleAIMapper.mapGenerateContentRequest(params);\n  }\n  return makeRequest(\n    {\n      model,\n      task: Task.GENERATE_CONTENT,\n      apiSettings,\n      stream: false,\n      requestOptions\n    },\n    JSON.stringify(params)\n  );\n}\n\nexport async function templateGenerateContent(\n  apiSettings: ApiSettings,\n  templateId: string,\n  templateParams: object,\n  requestOptions?: RequestOptions\n): Promise<GenerateContentResult> {\n  const response = await makeRequest(\n    {\n      task: ServerPromptTemplateTask.TEMPLATE_GENERATE_CONTENT,\n      templateId,\n      apiSettings,\n      stream: false,\n      requestOptions\n    },\n    JSON.stringify(templateParams)\n  );\n  const generateContentResponse = await processGenerateContentResponse(\n    response,\n    apiSettings\n  );\n  const enhancedResponse = createEnhancedContentResponse(\n    generateContentResponse\n  );\n  return {\n    response: enhancedResponse\n  };\n}\n\nexport async function templateGenerateContentStream(\n  apiSettings: ApiSettings,\n  templateId: string,\n  templateParams: object,\n  requestOptions?: RequestOptions\n): Promise<GenerateContentStreamResult> {\n  const response = await makeRequest(\n    {\n      task: ServerPromptTemplateTask.TEMPLATE_STREAM_GENERATE_CONTENT,\n      templateId,\n      apiSettings,\n      stream: true,\n      requestOptions\n    },\n    JSON.stringify(templateParams)\n  );\n  return processStream(response, apiSettings);\n}\n\nexport async function generateContent(\n  apiSettings: ApiSettings,\n  model: string,\n  params: GenerateContentRequest,\n  chromeAdapter?: ChromeAdapter,\n  requestOptions?: RequestOptions\n): Promise<GenerateContentResult> {\n  const callResult = await callCloudOrDevice(\n    params,\n    chromeAdapter,\n    () => chromeAdapter!.generateContent(params),\n    () => generateContentOnCloud(apiSettings, model, params, requestOptions)\n  );\n  const generateContentResponse = await processGenerateContentResponse(\n    callResult.response,\n    apiSettings\n  );\n  const enhancedResponse = createEnhancedContentResponse(\n    generateContentResponse,\n    callResult.inferenceSource\n  );\n  return {\n    response: enhancedResponse\n  };\n}\n\nasync function processGenerateContentResponse(\n  response: Response,\n  apiSettings: ApiSettings\n): Promise<GenerateContentResponse> {\n  const responseJson = await response.json();\n  if (apiSettings.backend.backendType === BackendType.GOOGLE_AI) {\n    return GoogleAIMapper.mapGenerateContentResponse(responseJson);\n  } else {\n    return responseJson;\n  }\n}\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Content, GenerateContentRequest, Part, AIErrorCode } from '../types';\nimport { AIError } from '../errors';\nimport { ImagenGenerationParams, PredictRequestBody } from '../types/internal';\n\nexport function formatSystemInstruction(\n  input?: string | Part | Content\n): Content | undefined {\n  // null or undefined\n  if (input == null) {\n    return undefined;\n  } else if (typeof input === 'string') {\n    return { role: 'system', parts: [{ text: input }] } as Content;\n  } else if ((input as Part).text) {\n    return { role: 'system', parts: [input as Part] };\n  } else if ((input as Content).parts) {\n    if (!(input as Content).role) {\n      return { role: 'system', parts: (input as Content).parts };\n    } else {\n      return input as Content;\n    }\n  }\n}\n\nexport function formatNewContent(\n  request: string | Array<string | Part>\n): Content {\n  let newParts: Part[] = [];\n  if (typeof request === 'string') {\n    newParts = [{ text: request }];\n  } else {\n    for (const partOrString of request) {\n      if (typeof partOrString === 'string') {\n        newParts.push({ text: partOrString });\n      } else {\n        newParts.push(partOrString);\n      }\n    }\n  }\n  return assignRoleToPartsAndValidateSendMessageRequest(newParts);\n}\n\n/**\n * When multiple Part types (i.e. FunctionResponsePart and TextPart) are\n * passed in a single Part array, we may need to assign different roles to each\n * part. Currently only FunctionResponsePart requires a role other than 'user'.\n * @private\n * @param parts Array of parts to pass to the model\n * @returns Array of content items\n */\nfunction assignRoleToPartsAndValidateSendMessageRequest(\n  parts: Part[]\n): Content {\n  const userContent: Content = { role: 'user', parts: [] };\n  const functionContent: Content = { role: 'function', parts: [] };\n  let hasUserContent = false;\n  let hasFunctionContent = false;\n  for (const part of parts) {\n    if ('functionResponse' in part) {\n      functionContent.parts.push(part);\n      hasFunctionContent = true;\n    } else {\n      userContent.parts.push(part);\n      hasUserContent = true;\n    }\n  }\n\n  if (hasUserContent && hasFunctionContent) {\n    throw new AIError(\n      AIErrorCode.INVALID_CONTENT,\n      'Within a single message, FunctionResponse cannot be mixed with other type of Part in the request for sending chat message.'\n    );\n  }\n\n  if (!hasUserContent && !hasFunctionContent) {\n    throw new AIError(\n      AIErrorCode.INVALID_CONTENT,\n      'No Content is provided for sending chat message.'\n    );\n  }\n\n  if (hasUserContent) {\n    return userContent;\n  }\n\n  return functionContent;\n}\n\nexport function formatGenerateContentInput(\n  params: GenerateContentRequest | string | Array<string | Part>\n): GenerateContentRequest {\n  let formattedRequest: GenerateContentRequest;\n  if ((params as GenerateContentRequest).contents) {\n    formattedRequest = params as GenerateContentRequest;\n  } else {\n    // Array or string\n    const content = formatNewContent(params as string | Array<string | Part>);\n    formattedRequest = { contents: [content] };\n  }\n  if ((params as GenerateContentRequest).systemInstruction) {\n    formattedRequest.systemInstruction = formatSystemInstruction(\n      (params as GenerateContentRequest).systemInstruction\n    );\n  }\n  return formattedRequest;\n}\n\n/**\n * Convert the user-defined parameters in {@link ImagenGenerationParams} to the format\n * that is expected from the REST API.\n *\n * @internal\n */\nexport function createPredictRequestBody(\n  prompt: string,\n  {\n    gcsURI,\n    imageFormat,\n    addWatermark,\n    numberOfImages = 1,\n    negativePrompt,\n    aspectRatio,\n    safetyFilterLevel,\n    personFilterLevel\n  }: ImagenGenerationParams\n): PredictRequestBody {\n  // Properties that are undefined will be omitted from the JSON string that is sent in the request.\n  const body: PredictRequestBody = {\n    instances: [\n      {\n        prompt\n      }\n    ],\n    parameters: {\n      storageUri: gcsURI,\n      negativePrompt,\n      sampleCount: numberOfImages,\n      aspectRatio,\n      outputOptions: imageFormat,\n      addWatermark,\n      safetyFilterLevel,\n      personGeneration: personFilterLevel,\n      includeRaiReason: true,\n      includeSafetyAttributes: true\n    }\n  };\n  return body;\n}\n","/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Content, POSSIBLE_ROLES, Part, Role, AIErrorCode } from '../types';\nimport { AIError } from '../errors';\n\n// https://ai.google.dev/api/rest/v1beta/Content#part\n\nconst VALID_PART_FIELDS: Array<keyof Part> = [\n  'text',\n  'inlineData',\n  'functionCall',\n  'functionResponse',\n  'thought',\n  'thoughtSignature'\n];\n\nconst VALID_PARTS_PER_ROLE: { [key in Role]: Array<keyof Part> } = {\n  user: ['text', 'inlineData'],\n  function: ['functionResponse'],\n  model: ['text', 'functionCall', 'thought', 'thoughtSignature'],\n  // System instructions shouldn't be in history anyway.\n  system: ['text']\n};\n\nconst VALID_PREVIOUS_CONTENT_ROLES: { [key in Role]: Role[] } = {\n  user: ['model'],\n  function: ['model'],\n  model: ['user', 'function'],\n  // System instructions shouldn't be in history.\n  system: []\n};\n\nexport function validateChatHistory(history: Content[]): void {\n  let prevContent: Content | null = null;\n  for (const currContent of history) {\n    const { role, parts } = currContent;\n    if (!prevContent && role !== 'user') {\n      throw new AIError(\n        AIErrorCode.INVALID_CONTENT,\n        `First Content should be with role 'user', got ${role}`\n      );\n    }\n    if (!POSSIBLE_ROLES.includes(role)) {\n      throw new AIError(\n        AIErrorCode.INVALID_CONTENT,\n        `Each item should include role field. Got ${role} but valid roles are: ${JSON.stringify(\n          POSSIBLE_ROLES\n        )}`\n      );\n    }\n\n    if (!Array.isArray(parts)) {\n      throw new AIError(\n        AIErrorCode.INVALID_CONTENT,\n        `Content should have 'parts' property with an array of Parts`\n      );\n    }\n\n    if (parts.length === 0) {\n      throw new AIError(\n        AIErrorCode.INVALID_CONTENT,\n        `Each Content should have at least one part`\n      );\n    }\n\n    const countFields: Record<keyof Part, number> = {\n      text: 0,\n      inlineData: 0,\n      functionCall: 0,\n      functionResponse: 0,\n      thought: 0,\n      thoughtSignature: 0,\n      executableCode: 0,\n      codeExecutionResult: 0\n    };\n\n    for (const part of parts) {\n      for (const key of VALID_PART_FIELDS) {\n        if (key in part) {\n          countFields[key] += 1;\n        }\n      }\n    }\n    const validParts = VALID_PARTS_PER_ROLE[role];\n    for (const key of VALID_PART_FIELDS) {\n      if (!validParts.includes(key) && countFields[key] > 0) {\n        throw new AIError(\n          AIErrorCode.INVALID_CONTENT,\n          `Content with role '${role}' can't contain '${key}' part`\n        );\n      }\n    }\n\n    if (prevContent) {\n      const validPreviousContentRoles = VALID_PREVIOUS_CONTENT_ROLES[role];\n      if (!validPreviousContentRoles.includes(prevContent.role)) {\n        throw new AIError(\n          AIErrorCode.INVALID_CONTENT,\n          `Content with role '${role}' can't follow '${\n            prevContent.role\n          }'. Valid previous roles: ${JSON.stringify(\n            VALID_PREVIOUS_CONTENT_ROLES\n          )}`\n        );\n      }\n    }\n    prevContent = currContent;\n  